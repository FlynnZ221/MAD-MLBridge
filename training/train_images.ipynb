{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pickle5\n",
      "  Downloading pickle5-0.0.11.tar.gz (132 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.1/132.1 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: pickle5\n",
      "  Building wheel for pickle5 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pickle5: filename=pickle5-0.0.11-cp38-cp38-macosx_11_0_arm64.whl size=122256 sha256=0340c2911a444999869707caff912384bdc6910ab81769e2be2d252224939234\n",
      "  Stored in directory: /Users/yanicewan/Library/Caches/pip/wheels/25/d4/61/dbd8edd1a0d656be7b4267c85db3b61951eb60016a0154a122\n",
      "Successfully built pickle5\n",
      "Installing collected packages: pickle5\n",
      "Successfully installed pickle5-0.0.11\n"
     ]
    }
   ],
   "source": [
    "!pip install pickle5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import pickle5 as pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.layers import Dense,Dropout,MaxPooling2D, Flatten, Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_random_seeds(seed):\n",
    "    os.environ['PYTHONHASHSEED']=str(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../preprocess_images/img_train.pkl\", \"rb\") as fh:\n",
    "    data = pickle.load(fh)\n",
    "X_train_ = pd.DataFrame(data)[\"img_array\"] \n",
    "\n",
    "with open(\"../preprocess_images/img_test.pkl\", \"rb\") as fh:\n",
    "    data = pickle.load(fh)\n",
    "X_test_ = pd.DataFrame(data)[\"img_array\"]\n",
    "\n",
    "with open(\"../preprocess_images/img_y_train.pkl\", \"rb\") as fh:\n",
    "    data = pickle.load(fh)\n",
    "y_train = np.array(pd.DataFrame(data)[\"label\"].values.astype(np.float32)).flatten()\n",
    "\n",
    "with open(\"../preprocess_images/img_y_test.pkl\", \"rb\") as fh:\n",
    "    data = pickle.load(fh)\n",
    "y_test = np.array(pd.DataFrame(data)[\"label\"].values.astype(np.float32)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_40 (Conv2D)          (None, 70, 70, 100)       2800      \n",
      "                                                                 \n",
      " max_pooling2d_40 (MaxPooli  (None, 35, 35, 100)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_44 (Dropout)        (None, 35, 35, 100)       0         \n",
      "                                                                 \n",
      " conv2d_41 (Conv2D)          (None, 33, 33, 100)       90100     \n",
      "                                                                 \n",
      " max_pooling2d_41 (MaxPooli  (None, 16, 16, 100)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_45 (Dropout)        (None, 16, 16, 100)       0         \n",
      "                                                                 \n",
      " flatten_18 (Flatten)        (None, 25600)             0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 3)                 76803     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 169703 (662.90 KB)\n",
      "Trainable params: 169703 (662.90 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "11/11 [==============================] - 3s 277ms/step - loss: 202.6033 - sparse_categorical_accuracy: 0.3739 - val_loss: 62.3530 - val_sparse_categorical_accuracy: 0.6154 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 3s 255ms/step - loss: 119.2223 - sparse_categorical_accuracy: 0.4319 - val_loss: 78.2598 - val_sparse_categorical_accuracy: 0.3590 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 3s 243ms/step - loss: 136.8998 - sparse_categorical_accuracy: 0.4232 - val_loss: 75.9966 - val_sparse_categorical_accuracy: 0.2821 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 3s 271ms/step - loss: 104.3206 - sparse_categorical_accuracy: 0.4812 - val_loss: 84.4881 - val_sparse_categorical_accuracy: 0.2564 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 3s 239ms/step - loss: 89.8597 - sparse_categorical_accuracy: 0.4696 - val_loss: 41.2798 - val_sparse_categorical_accuracy: 0.4615 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 3s 233ms/step - loss: 91.5144 - sparse_categorical_accuracy: 0.4899 - val_loss: 32.8781 - val_sparse_categorical_accuracy: 0.5385 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 3s 236ms/step - loss: 85.4225 - sparse_categorical_accuracy: 0.4609 - val_loss: 48.0310 - val_sparse_categorical_accuracy: 0.5128 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 3s 231ms/step - loss: 71.4975 - sparse_categorical_accuracy: 0.4870 - val_loss: 61.6350 - val_sparse_categorical_accuracy: 0.2564 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 3s 238ms/step - loss: 79.2768 - sparse_categorical_accuracy: 0.4522 - val_loss: 37.8523 - val_sparse_categorical_accuracy: 0.5385 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 3s 237ms/step - loss: 67.7544 - sparse_categorical_accuracy: 0.4551 - val_loss: 37.1477 - val_sparse_categorical_accuracy: 0.5641 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 3s 237ms/step - loss: 61.7300 - sparse_categorical_accuracy: 0.4812 - val_loss: 57.8842 - val_sparse_categorical_accuracy: 0.2821 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 4s 372ms/step - loss: 71.9588 - sparse_categorical_accuracy: 0.4493 - val_loss: 34.6575 - val_sparse_categorical_accuracy: 0.4872 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 3s 263ms/step - loss: 48.3250 - sparse_categorical_accuracy: 0.5420 - val_loss: 23.9298 - val_sparse_categorical_accuracy: 0.6410 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 3s 241ms/step - loss: 62.5409 - sparse_categorical_accuracy: 0.4928 - val_loss: 27.9413 - val_sparse_categorical_accuracy: 0.5641 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 3s 256ms/step - loss: 53.5553 - sparse_categorical_accuracy: 0.5420 - val_loss: 29.2935 - val_sparse_categorical_accuracy: 0.4103 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 3s 236ms/step - loss: 50.0785 - sparse_categorical_accuracy: 0.5217 - val_loss: 29.4645 - val_sparse_categorical_accuracy: 0.4615 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 3s 231ms/step - loss: 46.3021 - sparse_categorical_accuracy: 0.5507 - val_loss: 20.7544 - val_sparse_categorical_accuracy: 0.6154 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 3s 229ms/step - loss: 48.0919 - sparse_categorical_accuracy: 0.4928 - val_loss: 24.2379 - val_sparse_categorical_accuracy: 0.4872 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 3s 234ms/step - loss: 38.8950 - sparse_categorical_accuracy: 0.5304 - val_loss: 39.3191 - val_sparse_categorical_accuracy: 0.3077 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 3s 239ms/step - loss: 35.9724 - sparse_categorical_accuracy: 0.5681 - val_loss: 17.8695 - val_sparse_categorical_accuracy: 0.6154 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 3s 233ms/step - loss: 41.6001 - sparse_categorical_accuracy: 0.5304 - val_loss: 24.3670 - val_sparse_categorical_accuracy: 0.4359 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 3s 236ms/step - loss: 35.5485 - sparse_categorical_accuracy: 0.5594 - val_loss: 21.3400 - val_sparse_categorical_accuracy: 0.5128 - lr: 1.0000e-04\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 3s 244ms/step - loss: 35.9709 - sparse_categorical_accuracy: 0.5275 - val_loss: 18.0144 - val_sparse_categorical_accuracy: 0.6154 - lr: 1.0000e-04\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 3s 237ms/step - loss: 33.7860 - sparse_categorical_accuracy: 0.5565 - val_loss: 25.2082 - val_sparse_categorical_accuracy: 0.4103 - lr: 1.0000e-04\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 3s 240ms/step - loss: 30.7297 - sparse_categorical_accuracy: 0.5217 - val_loss: 17.8029 - val_sparse_categorical_accuracy: 0.5897 - lr: 1.0000e-04\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 3s 264ms/step - loss: 25.7306 - sparse_categorical_accuracy: 0.5623 - val_loss: 19.1340 - val_sparse_categorical_accuracy: 0.5641 - lr: 1.0000e-04\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 3s 233ms/step - loss: 29.0215 - sparse_categorical_accuracy: 0.5797 - val_loss: 16.3667 - val_sparse_categorical_accuracy: 0.5385 - lr: 1.0000e-04\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 3s 230ms/step - loss: 34.1855 - sparse_categorical_accuracy: 0.5304 - val_loss: 20.1376 - val_sparse_categorical_accuracy: 0.5385 - lr: 1.0000e-04\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 3s 234ms/step - loss: 28.4286 - sparse_categorical_accuracy: 0.5884 - val_loss: 16.3236 - val_sparse_categorical_accuracy: 0.5641 - lr: 1.0000e-04\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 3s 324ms/step - loss: 19.3461 - sparse_categorical_accuracy: 0.5971 - val_loss: 19.7180 - val_sparse_categorical_accuracy: 0.5128 - lr: 1.0000e-04\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 3s 263ms/step - loss: 26.9694 - sparse_categorical_accuracy: 0.5797 - val_loss: 18.2185 - val_sparse_categorical_accuracy: 0.5641 - lr: 1.0000e-04\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 3s 254ms/step - loss: 23.2458 - sparse_categorical_accuracy: 0.5797 - val_loss: 17.6015 - val_sparse_categorical_accuracy: 0.5128 - lr: 1.0000e-04\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 4s 397ms/step - loss: 23.5237 - sparse_categorical_accuracy: 0.5884 - val_loss: 15.2206 - val_sparse_categorical_accuracy: 0.4615 - lr: 1.0000e-04\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 3s 276ms/step - loss: 19.5569 - sparse_categorical_accuracy: 0.5942 - val_loss: 18.0836 - val_sparse_categorical_accuracy: 0.5385 - lr: 1.0000e-04\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 3s 256ms/step - loss: 23.0434 - sparse_categorical_accuracy: 0.5826 - val_loss: 20.2919 - val_sparse_categorical_accuracy: 0.3846 - lr: 1.0000e-04\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 3s 278ms/step - loss: 25.9611 - sparse_categorical_accuracy: 0.5333 - val_loss: 11.1535 - val_sparse_categorical_accuracy: 0.5128 - lr: 1.0000e-04\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 3s 247ms/step - loss: 22.1073 - sparse_categorical_accuracy: 0.5768 - val_loss: 15.6230 - val_sparse_categorical_accuracy: 0.4615 - lr: 1.0000e-04\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 3s 264ms/step - loss: 14.6431 - sparse_categorical_accuracy: 0.6145 - val_loss: 19.8438 - val_sparse_categorical_accuracy: 0.3846 - lr: 1.0000e-04\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 3s 237ms/step - loss: 18.8944 - sparse_categorical_accuracy: 0.6319 - val_loss: 13.8257 - val_sparse_categorical_accuracy: 0.4615 - lr: 1.0000e-04\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 3s 242ms/step - loss: 15.3286 - sparse_categorical_accuracy: 0.6145 - val_loss: 13.1168 - val_sparse_categorical_accuracy: 0.4615 - lr: 1.0000e-04\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 3s 229ms/step - loss: 21.8940 - sparse_categorical_accuracy: 0.6000 - val_loss: 14.1318 - val_sparse_categorical_accuracy: 0.4359 - lr: 1.0000e-04\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 3s 229ms/step - loss: 20.9534 - sparse_categorical_accuracy: 0.5652 - val_loss: 18.9341 - val_sparse_categorical_accuracy: 0.4103 - lr: 1.0000e-04\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 3s 234ms/step - loss: 15.4633 - sparse_categorical_accuracy: 0.6000 - val_loss: 14.1666 - val_sparse_categorical_accuracy: 0.4359 - lr: 1.0000e-04\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 16.3304 - sparse_categorical_accuracy: 0.5768\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "11/11 [==============================] - 3s 231ms/step - loss: 16.3304 - sparse_categorical_accuracy: 0.5768 - val_loss: 16.8967 - val_sparse_categorical_accuracy: 0.4359 - lr: 1.0000e-04\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 3s 238ms/step - loss: 15.9579 - sparse_categorical_accuracy: 0.6493 - val_loss: 15.3100 - val_sparse_categorical_accuracy: 0.4359 - lr: 5.0000e-05\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 3s 231ms/step - loss: 16.1467 - sparse_categorical_accuracy: 0.5971 - val_loss: 18.5104 - val_sparse_categorical_accuracy: 0.4103 - lr: 5.0000e-05\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 3s 238ms/step - loss: 15.3379 - sparse_categorical_accuracy: 0.5739 - val_loss: 15.4772 - val_sparse_categorical_accuracy: 0.4359 - lr: 5.0000e-05\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 3s 234ms/step - loss: 14.2571 - sparse_categorical_accuracy: 0.6145 - val_loss: 14.6335 - val_sparse_categorical_accuracy: 0.4615 - lr: 5.0000e-05\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 4s 390ms/step - loss: 16.8723 - sparse_categorical_accuracy: 0.6203 - val_loss: 17.5651 - val_sparse_categorical_accuracy: 0.4103 - lr: 5.0000e-05\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 3s 231ms/step - loss: 14.0284 - sparse_categorical_accuracy: 0.6232 - val_loss: 15.4392 - val_sparse_categorical_accuracy: 0.4359 - lr: 5.0000e-05\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 3s 233ms/step - loss: 14.7783 - sparse_categorical_accuracy: 0.6203 - val_loss: 16.0640 - val_sparse_categorical_accuracy: 0.4872 - lr: 5.0000e-05\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 16.9671 - sparse_categorical_accuracy: 0.6000\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "11/11 [==============================] - 3s 244ms/step - loss: 16.9671 - sparse_categorical_accuracy: 0.6000 - val_loss: 17.1604 - val_sparse_categorical_accuracy: 0.4359 - lr: 5.0000e-05\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 3s 229ms/step - loss: 14.3342 - sparse_categorical_accuracy: 0.5971 - val_loss: 17.6778 - val_sparse_categorical_accuracy: 0.4359 - lr: 2.5000e-05\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 3s 234ms/step - loss: 17.1290 - sparse_categorical_accuracy: 0.6145 - val_loss: 16.0527 - val_sparse_categorical_accuracy: 0.5128 - lr: 2.5000e-05\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 3s 230ms/step - loss: 15.5491 - sparse_categorical_accuracy: 0.6435 - val_loss: 14.7859 - val_sparse_categorical_accuracy: 0.4872 - lr: 2.5000e-05\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 2s 229ms/step - loss: 12.8661 - sparse_categorical_accuracy: 0.6319 - val_loss: 15.0284 - val_sparse_categorical_accuracy: 0.5128 - lr: 2.5000e-05\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 11.4414 - sparse_categorical_accuracy: 0.6667 - val_loss: 14.4980 - val_sparse_categorical_accuracy: 0.4872 - lr: 2.5000e-05\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 3s 266ms/step - loss: 10.6761 - sparse_categorical_accuracy: 0.6522 - val_loss: 15.2656 - val_sparse_categorical_accuracy: 0.4872 - lr: 2.5000e-05\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 3s 284ms/step - loss: 13.5692 - sparse_categorical_accuracy: 0.6464 - val_loss: 15.3699 - val_sparse_categorical_accuracy: 0.4872 - lr: 2.5000e-05\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 13.6006 - sparse_categorical_accuracy: 0.6174\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "11/11 [==============================] - 3s 243ms/step - loss: 13.6006 - sparse_categorical_accuracy: 0.6174 - val_loss: 15.9040 - val_sparse_categorical_accuracy: 0.4872 - lr: 2.5000e-05\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 3s 233ms/step - loss: 12.3473 - sparse_categorical_accuracy: 0.5971 - val_loss: 15.3753 - val_sparse_categorical_accuracy: 0.4872 - lr: 1.2500e-05\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 13.9688 - sparse_categorical_accuracy: 0.5971 - val_loss: 15.4671 - val_sparse_categorical_accuracy: 0.4872 - lr: 1.2500e-05\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 15.9027 - sparse_categorical_accuracy: 0.5797 - val_loss: 15.5052 - val_sparse_categorical_accuracy: 0.4872 - lr: 1.2500e-05\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 13.7572 - sparse_categorical_accuracy: 0.5971 - val_loss: 15.0245 - val_sparse_categorical_accuracy: 0.4872 - lr: 1.2500e-05\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 3s 233ms/step - loss: 14.1212 - sparse_categorical_accuracy: 0.6435 - val_loss: 14.4694 - val_sparse_categorical_accuracy: 0.4872 - lr: 1.2500e-05\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 3s 243ms/step - loss: 11.1158 - sparse_categorical_accuracy: 0.6812 - val_loss: 14.0703 - val_sparse_categorical_accuracy: 0.5128 - lr: 1.2500e-05\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 3s 230ms/step - loss: 12.7150 - sparse_categorical_accuracy: 0.6232 - val_loss: 14.7279 - val_sparse_categorical_accuracy: 0.4872 - lr: 1.2500e-05\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 13.2652 - sparse_categorical_accuracy: 0.6261\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "11/11 [==============================] - 3s 232ms/step - loss: 13.2652 - sparse_categorical_accuracy: 0.6261 - val_loss: 15.0589 - val_sparse_categorical_accuracy: 0.4872 - lr: 1.2500e-05\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 3s 231ms/step - loss: 12.9577 - sparse_categorical_accuracy: 0.5971 - val_loss: 15.0718 - val_sparse_categorical_accuracy: 0.4872 - lr: 6.2500e-06\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 3s 236ms/step - loss: 12.2427 - sparse_categorical_accuracy: 0.5913 - val_loss: 14.8101 - val_sparse_categorical_accuracy: 0.4872 - lr: 6.2500e-06\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 3s 229ms/step - loss: 11.3178 - sparse_categorical_accuracy: 0.6203 - val_loss: 14.5720 - val_sparse_categorical_accuracy: 0.4872 - lr: 6.2500e-06\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 13.9970 - sparse_categorical_accuracy: 0.6348 - val_loss: 14.6274 - val_sparse_categorical_accuracy: 0.4872 - lr: 6.2500e-06\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 11.7472 - sparse_categorical_accuracy: 0.6464 - val_loss: 14.7061 - val_sparse_categorical_accuracy: 0.4872 - lr: 6.2500e-06\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 2s 229ms/step - loss: 10.1923 - sparse_categorical_accuracy: 0.6377 - val_loss: 14.6869 - val_sparse_categorical_accuracy: 0.4872 - lr: 6.2500e-06\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 12.0543 - sparse_categorical_accuracy: 0.6377 - val_loss: 14.6757 - val_sparse_categorical_accuracy: 0.4872 - lr: 6.2500e-06\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 12.4826 - sparse_categorical_accuracy: 0.6029\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "11/11 [==============================] - 3s 238ms/step - loss: 12.4826 - sparse_categorical_accuracy: 0.6029 - val_loss: 14.6268 - val_sparse_categorical_accuracy: 0.4872 - lr: 6.2500e-06\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 3s 232ms/step - loss: 10.9703 - sparse_categorical_accuracy: 0.6986 - val_loss: 14.9351 - val_sparse_categorical_accuracy: 0.4872 - lr: 3.1250e-06\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 2s 229ms/step - loss: 10.2997 - sparse_categorical_accuracy: 0.6348 - val_loss: 15.1050 - val_sparse_categorical_accuracy: 0.4872 - lr: 3.1250e-06\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 3s 249ms/step - loss: 13.4930 - sparse_categorical_accuracy: 0.6116 - val_loss: 15.0813 - val_sparse_categorical_accuracy: 0.4872 - lr: 3.1250e-06\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 13.6936 - sparse_categorical_accuracy: 0.6058 - val_loss: 14.8119 - val_sparse_categorical_accuracy: 0.4872 - lr: 3.1250e-06\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 11.2824 - sparse_categorical_accuracy: 0.6377 - val_loss: 14.6510 - val_sparse_categorical_accuracy: 0.4872 - lr: 3.1250e-06\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 4s 339ms/step - loss: 11.6771 - sparse_categorical_accuracy: 0.6232 - val_loss: 14.5589 - val_sparse_categorical_accuracy: 0.4872 - lr: 3.1250e-06\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 3s 234ms/step - loss: 12.4255 - sparse_categorical_accuracy: 0.6493 - val_loss: 14.6842 - val_sparse_categorical_accuracy: 0.4872 - lr: 3.1250e-06\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 10.9020 - sparse_categorical_accuracy: 0.6493\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "11/11 [==============================] - 3s 245ms/step - loss: 10.9020 - sparse_categorical_accuracy: 0.6493 - val_loss: 14.7282 - val_sparse_categorical_accuracy: 0.4872 - lr: 3.1250e-06\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 3s 236ms/step - loss: 11.0766 - sparse_categorical_accuracy: 0.6174 - val_loss: 14.7826 - val_sparse_categorical_accuracy: 0.4872 - lr: 1.5625e-06\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 3s 229ms/step - loss: 13.3551 - sparse_categorical_accuracy: 0.6406 - val_loss: 14.7888 - val_sparse_categorical_accuracy: 0.4872 - lr: 1.5625e-06\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 3s 233ms/step - loss: 11.9572 - sparse_categorical_accuracy: 0.6609 - val_loss: 14.7674 - val_sparse_categorical_accuracy: 0.4872 - lr: 1.5625e-06\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 3s 234ms/step - loss: 11.7272 - sparse_categorical_accuracy: 0.6406 - val_loss: 14.6726 - val_sparse_categorical_accuracy: 0.4872 - lr: 1.5625e-06\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 3s 255ms/step - loss: 10.4003 - sparse_categorical_accuracy: 0.6435 - val_loss: 14.6855 - val_sparse_categorical_accuracy: 0.4872 - lr: 1.5625e-06\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 3s 234ms/step - loss: 12.2275 - sparse_categorical_accuracy: 0.6580 - val_loss: 14.7973 - val_sparse_categorical_accuracy: 0.4872 - lr: 1.5625e-06\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 3s 230ms/step - loss: 13.6040 - sparse_categorical_accuracy: 0.5971 - val_loss: 14.9021 - val_sparse_categorical_accuracy: 0.4872 - lr: 1.5625e-06\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 9.9255 - sparse_categorical_accuracy: 0.6493\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 9.9255 - sparse_categorical_accuracy: 0.6493 - val_loss: 14.9627 - val_sparse_categorical_accuracy: 0.4872 - lr: 1.5625e-06\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 3s 236ms/step - loss: 10.5384 - sparse_categorical_accuracy: 0.6638 - val_loss: 14.9830 - val_sparse_categorical_accuracy: 0.4872 - lr: 7.8125e-07\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 3s 242ms/step - loss: 13.1727 - sparse_categorical_accuracy: 0.6290 - val_loss: 14.9911 - val_sparse_categorical_accuracy: 0.4872 - lr: 7.8125e-07\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 12.9285 - sparse_categorical_accuracy: 0.6000 - val_loss: 14.9843 - val_sparse_categorical_accuracy: 0.4872 - lr: 7.8125e-07\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 3s 239ms/step - loss: 9.8081 - sparse_categorical_accuracy: 0.6638 - val_loss: 14.9635 - val_sparse_categorical_accuracy: 0.4872 - lr: 7.8125e-07\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 3s 230ms/step - loss: 12.1565 - sparse_categorical_accuracy: 0.6261 - val_loss: 14.9263 - val_sparse_categorical_accuracy: 0.4872 - lr: 7.8125e-07\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 11.2854 - sparse_categorical_accuracy: 0.6348 - val_loss: 14.8910 - val_sparse_categorical_accuracy: 0.4872 - lr: 7.8125e-07\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 3s 248ms/step - loss: 11.4866 - sparse_categorical_accuracy: 0.6232 - val_loss: 14.8724 - val_sparse_categorical_accuracy: 0.4872 - lr: 7.8125e-07\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 10.5146 - sparse_categorical_accuracy: 0.6319\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "11/11 [==============================] - 3s 245ms/step - loss: 10.5146 - sparse_categorical_accuracy: 0.6319 - val_loss: 14.8596 - val_sparse_categorical_accuracy: 0.4872 - lr: 7.8125e-07\n",
      "Test loss: 5.717642784118652 / Test accuracy: 0.6190476417541504\n",
      "2/2 [==============================] - 0s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# y_test[y_test == 2] = -1\n",
    "# y_test[y_test == 1] = 2\n",
    "# y_test[y_test == -1] = 1\n",
    "\n",
    "# y_train[y_train == 2] = -1\n",
    "# y_train[y_train == 1] = 2\n",
    "# y_train[y_train == -1] = 1\n",
    "\n",
    "\n",
    "X_train = []\n",
    "X_test = []\n",
    "\n",
    "for i in range(len(X_train_)):\n",
    "    X_train.append(X_train_.values[i])\n",
    "    \n",
    "for i in range(len(X_test_)):\n",
    "    X_test.append(X_test_.values[i])\n",
    "\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "\n",
    "acc = []\n",
    "f1 = []\n",
    "precision = []\n",
    "recall = []\n",
    "seeds = random.sample(range(1, 200), 1)\n",
    "for seed in seeds:\n",
    "    reset_random_seeds(seed)\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(100, (3, 3),  activation='relu', input_shape=(72, 72, 3)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Conv2D(100, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(3, activation = \"softmax\"))\n",
    "    \n",
    "    \n",
    "    model.compile(Adam(learning_rate = 0.0001), \"sparse_categorical_crossentropy\", metrics = [\"sparse_categorical_accuracy\"])\n",
    "    \n",
    "    model.summary()\n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',  \n",
    "    factor=0.5,        \n",
    "    patience=8,      \n",
    "    min_lr=1e-11,      \n",
    "    verbose=1          \n",
    ")\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, \n",
    "        y_train, \n",
    "        epochs=100, \n",
    "        batch_size=32,\n",
    "        validation_split=0.1, \n",
    "        verbose=1,\n",
    "        callbacks=[reduce_lr]  \n",
    "    )\n",
    "\n",
    "    # history = model.fit(X_train, y_train, epochs=50, batch_size=32,validation_split=0.1, verbose=1) \n",
    "    \n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')\n",
    "    acc.append(score[1])\n",
    "    \n",
    "    test_predictions = model.predict(X_test)\n",
    "    test_label = to_categorical(y_test,3)\n",
    "\n",
    "    true_label= np.argmax(test_label, axis =1)\n",
    "\n",
    "    predicted_label= np.argmax(test_predictions, axis =1)\n",
    "    \n",
    "    cr = classification_report(true_label, predicted_label, output_dict=True)\n",
    "    precision.append(cr[\"macro avg\"][\"precision\"])\n",
    "    recall.append(cr[\"macro avg\"][\"recall\"])\n",
    "    f1.append(cr[\"macro avg\"][\"f1-score\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_47 (Conv2D)          (None, 70, 70, 100)       2800      \n",
      "                                                                 \n",
      " max_pooling2d_47 (MaxPooli  (None, 35, 35, 100)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_52 (Dropout)        (None, 35, 35, 100)       0         \n",
      "                                                                 \n",
      " conv2d_48 (Conv2D)          (None, 33, 33, 100)       90100     \n",
      "                                                                 \n",
      " max_pooling2d_48 (MaxPooli  (None, 16, 16, 100)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_53 (Dropout)        (None, 16, 16, 100)       0         \n",
      "                                                                 \n",
      " flatten_21 (Flatten)        (None, 25600)             0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 3)                 76803     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 169703 (662.90 KB)\n",
      "Trainable params: 169703 (662.90 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "11/11 [==============================] - 3s 265ms/step - loss: 185.3756 - sparse_categorical_accuracy: 0.3710 - val_loss: 72.1865 - val_sparse_categorical_accuracy: 0.6154 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 3s 311ms/step - loss: 107.3106 - sparse_categorical_accuracy: 0.4493 - val_loss: 58.7615 - val_sparse_categorical_accuracy: 0.2821 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 4s 284ms/step - loss: 96.3500 - sparse_categorical_accuracy: 0.4551 - val_loss: 46.3765 - val_sparse_categorical_accuracy: 0.2821 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 4s 415ms/step - loss: 114.5933 - sparse_categorical_accuracy: 0.4261 - val_loss: 115.4595 - val_sparse_categorical_accuracy: 0.2821 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 3s 262ms/step - loss: 96.7899 - sparse_categorical_accuracy: 0.4058 - val_loss: 48.5788 - val_sparse_categorical_accuracy: 0.2308 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 4s 382ms/step - loss: 95.9957 - sparse_categorical_accuracy: 0.4551 - val_loss: 46.2546 - val_sparse_categorical_accuracy: 0.2821 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 3s 250ms/step - loss: 75.9576 - sparse_categorical_accuracy: 0.4522 - val_loss: 55.2721 - val_sparse_categorical_accuracy: 0.2308 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 3s 270ms/step - loss: 69.6524 - sparse_categorical_accuracy: 0.5101 - val_loss: 32.5651 - val_sparse_categorical_accuracy: 0.3333 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 3s 236ms/step - loss: 70.8176 - sparse_categorical_accuracy: 0.5072 - val_loss: 30.2335 - val_sparse_categorical_accuracy: 0.3077 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 3s 260ms/step - loss: 64.9282 - sparse_categorical_accuracy: 0.5188 - val_loss: 56.3076 - val_sparse_categorical_accuracy: 0.2051 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 3s 253ms/step - loss: 58.1143 - sparse_categorical_accuracy: 0.4841 - val_loss: 21.3785 - val_sparse_categorical_accuracy: 0.3590 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 3s 264ms/step - loss: 56.6948 - sparse_categorical_accuracy: 0.4957 - val_loss: 39.2243 - val_sparse_categorical_accuracy: 0.3333 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 3s 240ms/step - loss: 57.4285 - sparse_categorical_accuracy: 0.5072 - val_loss: 33.7393 - val_sparse_categorical_accuracy: 0.3590 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 2s 224ms/step - loss: 41.6551 - sparse_categorical_accuracy: 0.5217 - val_loss: 23.8326 - val_sparse_categorical_accuracy: 0.3846 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 3s 295ms/step - loss: 51.1538 - sparse_categorical_accuracy: 0.4783 - val_loss: 33.5070 - val_sparse_categorical_accuracy: 0.3333 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 5s 477ms/step - loss: 42.6166 - sparse_categorical_accuracy: 0.5246 - val_loss: 34.5917 - val_sparse_categorical_accuracy: 0.2564 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 5s 389ms/step - loss: 44.9871 - sparse_categorical_accuracy: 0.5275 - val_loss: 12.0400 - val_sparse_categorical_accuracy: 0.5897 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 6s 577ms/step - loss: 49.2899 - sparse_categorical_accuracy: 0.4754 - val_loss: 31.4855 - val_sparse_categorical_accuracy: 0.3590 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 4s 309ms/step - loss: 45.4291 - sparse_categorical_accuracy: 0.5333 - val_loss: 19.9253 - val_sparse_categorical_accuracy: 0.3846 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 3s 285ms/step - loss: 36.1242 - sparse_categorical_accuracy: 0.5565 - val_loss: 31.8137 - val_sparse_categorical_accuracy: 0.3333 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 3s 288ms/step - loss: 27.6659 - sparse_categorical_accuracy: 0.5623 - val_loss: 22.7752 - val_sparse_categorical_accuracy: 0.4103 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 3s 266ms/step - loss: 42.8761 - sparse_categorical_accuracy: 0.5188 - val_loss: 43.3665 - val_sparse_categorical_accuracy: 0.2308 - lr: 1.0000e-04\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 3s 272ms/step - loss: 30.3447 - sparse_categorical_accuracy: 0.5565 - val_loss: 24.6106 - val_sparse_categorical_accuracy: 0.3590 - lr: 1.0000e-04\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 7s 593ms/step - loss: 38.5462 - sparse_categorical_accuracy: 0.5478 - val_loss: 36.3760 - val_sparse_categorical_accuracy: 0.2051 - lr: 1.0000e-04\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 25.8580 - sparse_categorical_accuracy: 0.5362\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "11/11 [==============================] - 3s 300ms/step - loss: 25.8580 - sparse_categorical_accuracy: 0.5362 - val_loss: 21.4138 - val_sparse_categorical_accuracy: 0.3590 - lr: 1.0000e-04\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 3s 291ms/step - loss: 22.7892 - sparse_categorical_accuracy: 0.5855 - val_loss: 34.7171 - val_sparse_categorical_accuracy: 0.2308 - lr: 5.0000e-05\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 3s 318ms/step - loss: 27.8882 - sparse_categorical_accuracy: 0.5826 - val_loss: 19.9687 - val_sparse_categorical_accuracy: 0.3590 - lr: 5.0000e-05\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 3s 294ms/step - loss: 21.1275 - sparse_categorical_accuracy: 0.5594 - val_loss: 25.2366 - val_sparse_categorical_accuracy: 0.3333 - lr: 5.0000e-05\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 3s 232ms/step - loss: 24.3883 - sparse_categorical_accuracy: 0.5449 - val_loss: 25.8280 - val_sparse_categorical_accuracy: 0.3333 - lr: 5.0000e-05\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 3s 228ms/step - loss: 23.8661 - sparse_categorical_accuracy: 0.5768 - val_loss: 25.0596 - val_sparse_categorical_accuracy: 0.3333 - lr: 5.0000e-05\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 3s 228ms/step - loss: 24.2321 - sparse_categorical_accuracy: 0.5333 - val_loss: 24.1998 - val_sparse_categorical_accuracy: 0.3333 - lr: 5.0000e-05\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 3s 235ms/step - loss: 24.7226 - sparse_categorical_accuracy: 0.5797 - val_loss: 24.6131 - val_sparse_categorical_accuracy: 0.3846 - lr: 5.0000e-05\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 23.2364 - sparse_categorical_accuracy: 0.5826\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "11/11 [==============================] - 3s 241ms/step - loss: 23.2364 - sparse_categorical_accuracy: 0.5826 - val_loss: 31.2452 - val_sparse_categorical_accuracy: 0.2308 - lr: 5.0000e-05\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 3s 248ms/step - loss: 27.2950 - sparse_categorical_accuracy: 0.5217 - val_loss: 23.1870 - val_sparse_categorical_accuracy: 0.3590 - lr: 2.5000e-05\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 3s 250ms/step - loss: 21.6959 - sparse_categorical_accuracy: 0.5710 - val_loss: 26.0560 - val_sparse_categorical_accuracy: 0.3333 - lr: 2.5000e-05\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 3s 269ms/step - loss: 22.9603 - sparse_categorical_accuracy: 0.5420 - val_loss: 28.3605 - val_sparse_categorical_accuracy: 0.2308 - lr: 2.5000e-05\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 4s 374ms/step - loss: 19.0059 - sparse_categorical_accuracy: 0.5942 - val_loss: 26.0469 - val_sparse_categorical_accuracy: 0.2821 - lr: 2.5000e-05\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 3s 254ms/step - loss: 20.2361 - sparse_categorical_accuracy: 0.6058 - val_loss: 25.2057 - val_sparse_categorical_accuracy: 0.3077 - lr: 2.5000e-05\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 3s 231ms/step - loss: 17.3544 - sparse_categorical_accuracy: 0.5594 - val_loss: 27.8194 - val_sparse_categorical_accuracy: 0.2564 - lr: 2.5000e-05\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 3s 314ms/step - loss: 22.7502 - sparse_categorical_accuracy: 0.5681 - val_loss: 26.2827 - val_sparse_categorical_accuracy: 0.3077 - lr: 2.5000e-05\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 16.3434 - sparse_categorical_accuracy: 0.6000\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "11/11 [==============================] - 3s 276ms/step - loss: 16.3434 - sparse_categorical_accuracy: 0.6000 - val_loss: 22.1462 - val_sparse_categorical_accuracy: 0.3846 - lr: 2.5000e-05\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 3s 285ms/step - loss: 25.3887 - sparse_categorical_accuracy: 0.5478 - val_loss: 22.5207 - val_sparse_categorical_accuracy: 0.3333 - lr: 1.2500e-05\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 3s 289ms/step - loss: 24.3699 - sparse_categorical_accuracy: 0.6029 - val_loss: 22.1547 - val_sparse_categorical_accuracy: 0.3333 - lr: 1.2500e-05\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 19.9656 - sparse_categorical_accuracy: 0.6000 - val_loss: 23.7857 - val_sparse_categorical_accuracy: 0.3333 - lr: 1.2500e-05\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 16.7895 - sparse_categorical_accuracy: 0.6145 - val_loss: 28.1979 - val_sparse_categorical_accuracy: 0.2821 - lr: 1.2500e-05\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 3s 286ms/step - loss: 20.5118 - sparse_categorical_accuracy: 0.5942 - val_loss: 27.8704 - val_sparse_categorical_accuracy: 0.2821 - lr: 1.2500e-05\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 3s 265ms/step - loss: 14.9654 - sparse_categorical_accuracy: 0.6116 - val_loss: 24.8548 - val_sparse_categorical_accuracy: 0.3077 - lr: 1.2500e-05\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 4s 343ms/step - loss: 19.9049 - sparse_categorical_accuracy: 0.5797 - val_loss: 20.7445 - val_sparse_categorical_accuracy: 0.3333 - lr: 1.2500e-05\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 18.8111 - sparse_categorical_accuracy: 0.5710\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "11/11 [==============================] - 3s 282ms/step - loss: 18.8111 - sparse_categorical_accuracy: 0.5710 - val_loss: 23.2518 - val_sparse_categorical_accuracy: 0.3333 - lr: 1.2500e-05\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 5s 511ms/step - loss: 17.2851 - sparse_categorical_accuracy: 0.6319 - val_loss: 23.6362 - val_sparse_categorical_accuracy: 0.3077 - lr: 6.2500e-06\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 5s 465ms/step - loss: 21.3193 - sparse_categorical_accuracy: 0.5739 - val_loss: 21.9923 - val_sparse_categorical_accuracy: 0.3333 - lr: 6.2500e-06\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 5s 496ms/step - loss: 18.0541 - sparse_categorical_accuracy: 0.6406 - val_loss: 22.1621 - val_sparse_categorical_accuracy: 0.3333 - lr: 6.2500e-06\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 4s 400ms/step - loss: 16.5239 - sparse_categorical_accuracy: 0.6203 - val_loss: 22.1610 - val_sparse_categorical_accuracy: 0.3333 - lr: 6.2500e-06\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 4s 339ms/step - loss: 22.3068 - sparse_categorical_accuracy: 0.6058 - val_loss: 24.7870 - val_sparse_categorical_accuracy: 0.3333 - lr: 6.2500e-06\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 4s 316ms/step - loss: 22.5888 - sparse_categorical_accuracy: 0.5565 - val_loss: 26.1913 - val_sparse_categorical_accuracy: 0.3077 - lr: 6.2500e-06\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 4s 285ms/step - loss: 20.3604 - sparse_categorical_accuracy: 0.5942 - val_loss: 27.4126 - val_sparse_categorical_accuracy: 0.2564 - lr: 6.2500e-06\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 20.6529 - sparse_categorical_accuracy: 0.5681\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "11/11 [==============================] - 3s 250ms/step - loss: 20.6529 - sparse_categorical_accuracy: 0.5681 - val_loss: 26.0303 - val_sparse_categorical_accuracy: 0.2564 - lr: 6.2500e-06\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 3s 252ms/step - loss: 21.3053 - sparse_categorical_accuracy: 0.6058 - val_loss: 24.6966 - val_sparse_categorical_accuracy: 0.2821 - lr: 3.1250e-06\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 3s 307ms/step - loss: 18.6856 - sparse_categorical_accuracy: 0.5826 - val_loss: 23.8763 - val_sparse_categorical_accuracy: 0.3077 - lr: 3.1250e-06\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 3s 254ms/step - loss: 16.1934 - sparse_categorical_accuracy: 0.6261 - val_loss: 23.5018 - val_sparse_categorical_accuracy: 0.3333 - lr: 3.1250e-06\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 17.1212 - sparse_categorical_accuracy: 0.6203 - val_loss: 23.1989 - val_sparse_categorical_accuracy: 0.3333 - lr: 3.1250e-06\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 2s 222ms/step - loss: 15.6644 - sparse_categorical_accuracy: 0.5739 - val_loss: 22.7691 - val_sparse_categorical_accuracy: 0.3333 - lr: 3.1250e-06\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 3s 275ms/step - loss: 18.3146 - sparse_categorical_accuracy: 0.6290 - val_loss: 22.8684 - val_sparse_categorical_accuracy: 0.3077 - lr: 3.1250e-06\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 4s 351ms/step - loss: 18.5202 - sparse_categorical_accuracy: 0.6058 - val_loss: 23.8819 - val_sparse_categorical_accuracy: 0.3077 - lr: 3.1250e-06\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 17.3208 - sparse_categorical_accuracy: 0.6087\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "11/11 [==============================] - 2s 224ms/step - loss: 17.3208 - sparse_categorical_accuracy: 0.6087 - val_loss: 24.4701 - val_sparse_categorical_accuracy: 0.3077 - lr: 3.1250e-06\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 3s 230ms/step - loss: 17.2399 - sparse_categorical_accuracy: 0.5884 - val_loss: 24.2874 - val_sparse_categorical_accuracy: 0.3077 - lr: 1.5625e-06\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 4s 385ms/step - loss: 17.4781 - sparse_categorical_accuracy: 0.5855 - val_loss: 23.9961 - val_sparse_categorical_accuracy: 0.2821 - lr: 1.5625e-06\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 5s 443ms/step - loss: 19.9798 - sparse_categorical_accuracy: 0.5768 - val_loss: 23.5673 - val_sparse_categorical_accuracy: 0.3077 - lr: 1.5625e-06\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 3s 262ms/step - loss: 19.3527 - sparse_categorical_accuracy: 0.5884 - val_loss: 23.5960 - val_sparse_categorical_accuracy: 0.3077 - lr: 1.5625e-06\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 4s 346ms/step - loss: 14.2973 - sparse_categorical_accuracy: 0.6029 - val_loss: 23.8640 - val_sparse_categorical_accuracy: 0.3077 - lr: 1.5625e-06\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 4s 379ms/step - loss: 16.9461 - sparse_categorical_accuracy: 0.5884 - val_loss: 23.6488 - val_sparse_categorical_accuracy: 0.3077 - lr: 1.5625e-06\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 3s 271ms/step - loss: 20.3083 - sparse_categorical_accuracy: 0.5884 - val_loss: 23.2248 - val_sparse_categorical_accuracy: 0.3333 - lr: 1.5625e-06\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 18.8329 - sparse_categorical_accuracy: 0.5855\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "11/11 [==============================] - 3s 317ms/step - loss: 18.8329 - sparse_categorical_accuracy: 0.5855 - val_loss: 23.3318 - val_sparse_categorical_accuracy: 0.3333 - lr: 1.5625e-06\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 3s 266ms/step - loss: 17.9725 - sparse_categorical_accuracy: 0.6029 - val_loss: 23.4271 - val_sparse_categorical_accuracy: 0.3077 - lr: 7.8125e-07\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 3s 275ms/step - loss: 19.3344 - sparse_categorical_accuracy: 0.6290 - val_loss: 23.4988 - val_sparse_categorical_accuracy: 0.3077 - lr: 7.8125e-07\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 3s 250ms/step - loss: 17.1913 - sparse_categorical_accuracy: 0.5942 - val_loss: 23.6649 - val_sparse_categorical_accuracy: 0.3077 - lr: 7.8125e-07\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 4s 363ms/step - loss: 19.5937 - sparse_categorical_accuracy: 0.6145 - val_loss: 23.6946 - val_sparse_categorical_accuracy: 0.3077 - lr: 7.8125e-07\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 5s 316ms/step - loss: 17.7186 - sparse_categorical_accuracy: 0.5855 - val_loss: 23.6530 - val_sparse_categorical_accuracy: 0.3077 - lr: 7.8125e-07\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 3s 272ms/step - loss: 23.2901 - sparse_categorical_accuracy: 0.5391 - val_loss: 23.9862 - val_sparse_categorical_accuracy: 0.3077 - lr: 7.8125e-07\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 4s 316ms/step - loss: 14.8987 - sparse_categorical_accuracy: 0.6116 - val_loss: 24.0596 - val_sparse_categorical_accuracy: 0.3077 - lr: 7.8125e-07\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 18.7306 - sparse_categorical_accuracy: 0.5768\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "11/11 [==============================] - 3s 243ms/step - loss: 18.7306 - sparse_categorical_accuracy: 0.5768 - val_loss: 23.8966 - val_sparse_categorical_accuracy: 0.3077 - lr: 7.8125e-07\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 3s 258ms/step - loss: 21.7728 - sparse_categorical_accuracy: 0.5681 - val_loss: 23.8394 - val_sparse_categorical_accuracy: 0.3077 - lr: 3.9062e-07\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 3s 298ms/step - loss: 18.2411 - sparse_categorical_accuracy: 0.6116 - val_loss: 23.8663 - val_sparse_categorical_accuracy: 0.3077 - lr: 3.9062e-07\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 3s 303ms/step - loss: 22.2797 - sparse_categorical_accuracy: 0.5507 - val_loss: 23.9206 - val_sparse_categorical_accuracy: 0.3077 - lr: 3.9062e-07\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 6s 522ms/step - loss: 18.9880 - sparse_categorical_accuracy: 0.6000 - val_loss: 23.9417 - val_sparse_categorical_accuracy: 0.3077 - lr: 3.9062e-07\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 3s 291ms/step - loss: 20.2303 - sparse_categorical_accuracy: 0.6116 - val_loss: 23.9018 - val_sparse_categorical_accuracy: 0.3077 - lr: 3.9062e-07\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 4s 359ms/step - loss: 17.4931 - sparse_categorical_accuracy: 0.5913 - val_loss: 23.8042 - val_sparse_categorical_accuracy: 0.3077 - lr: 3.9062e-07\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 4s 383ms/step - loss: 17.2940 - sparse_categorical_accuracy: 0.6232 - val_loss: 23.6823 - val_sparse_categorical_accuracy: 0.3333 - lr: 3.9062e-07\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 15.9547 - sparse_categorical_accuracy: 0.6000\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "11/11 [==============================] - 3s 257ms/step - loss: 15.9547 - sparse_categorical_accuracy: 0.6000 - val_loss: 23.5795 - val_sparse_categorical_accuracy: 0.3333 - lr: 3.9062e-07\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 3s 290ms/step - loss: 15.8277 - sparse_categorical_accuracy: 0.6145 - val_loss: 23.5518 - val_sparse_categorical_accuracy: 0.3333 - lr: 1.9531e-07\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 3s 271ms/step - loss: 17.7195 - sparse_categorical_accuracy: 0.5623 - val_loss: 23.5383 - val_sparse_categorical_accuracy: 0.3333 - lr: 1.9531e-07\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 3s 302ms/step - loss: 21.3316 - sparse_categorical_accuracy: 0.5333 - val_loss: 23.5872 - val_sparse_categorical_accuracy: 0.3333 - lr: 1.9531e-07\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 3s 310ms/step - loss: 14.9200 - sparse_categorical_accuracy: 0.5913 - val_loss: 23.6292 - val_sparse_categorical_accuracy: 0.3333 - lr: 1.9531e-07\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 3s 247ms/step - loss: 14.7072 - sparse_categorical_accuracy: 0.6232 - val_loss: 23.5705 - val_sparse_categorical_accuracy: 0.3333 - lr: 1.9531e-07\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 3s 306ms/step - loss: 18.0696 - sparse_categorical_accuracy: 0.6029 - val_loss: 23.5075 - val_sparse_categorical_accuracy: 0.3333 - lr: 1.9531e-07\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 3s 249ms/step - loss: 15.9667 - sparse_categorical_accuracy: 0.5913 - val_loss: 23.4228 - val_sparse_categorical_accuracy: 0.3333 - lr: 1.9531e-07\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 17.2197 - sparse_categorical_accuracy: 0.6377\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "11/11 [==============================] - 3s 251ms/step - loss: 17.2197 - sparse_categorical_accuracy: 0.6377 - val_loss: 23.4359 - val_sparse_categorical_accuracy: 0.3333 - lr: 1.9531e-07\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 3s 259ms/step - loss: 16.1621 - sparse_categorical_accuracy: 0.5971 - val_loss: 23.4375 - val_sparse_categorical_accuracy: 0.3333 - lr: 9.7656e-08\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 3s 254ms/step - loss: 18.6126 - sparse_categorical_accuracy: 0.5797 - val_loss: 23.4332 - val_sparse_categorical_accuracy: 0.3333 - lr: 9.7656e-08\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 3s 234ms/step - loss: 21.6747 - sparse_categorical_accuracy: 0.5710 - val_loss: 23.4718 - val_sparse_categorical_accuracy: 0.3333 - lr: 9.7656e-08\n",
      "Test loss: 5.2487969398498535 / Test accuracy: 0.7142857313156128\n",
      "WARNING:tensorflow:6 out of the last 21 calls to <function Model.make_predict_function.<locals>.predict_function at 0x28f90daf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 21 calls to <function Model.make_predict_function.<locals>.predict_function at 0x28f90daf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 18ms/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# y_test[y_test == 2] = -1\n",
    "# y_test[y_test == 1] = 2\n",
    "# y_test[y_test == -1] = 1\n",
    "\n",
    "# y_train[y_train == 2] = -1\n",
    "# y_train[y_train == 1] = 2\n",
    "# y_train[y_train == -1] = 1\n",
    "\n",
    "\n",
    "X_train = []\n",
    "X_test = []\n",
    "\n",
    "for i in range(len(X_train_)):\n",
    "    X_train.append(X_train_.values[i])\n",
    "    \n",
    "for i in range(len(X_test_)):\n",
    "    X_test.append(X_test_.values[i])\n",
    "\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "\n",
    "acc = []\n",
    "f1 = []\n",
    "precision = []\n",
    "recall = []\n",
    "seeds = random.sample(range(1, 200), 1)\n",
    "for seed in seeds:\n",
    "    reset_random_seeds(seed)\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(100, (3, 3),  activation='relu', input_shape=(72, 72, 3)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Conv2D(100, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(3, activation = \"softmax\"))\n",
    "    \n",
    "    \n",
    "    model.compile(Adam(learning_rate = 0.0001), \"sparse_categorical_crossentropy\", metrics = [\"sparse_categorical_accuracy\"])\n",
    "    \n",
    "    model.summary()\n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',  \n",
    "    factor=0.5,        \n",
    "    patience=8,      \n",
    "    min_lr=1e-11,      \n",
    "    verbose=1          \n",
    ")\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, \n",
    "        y_train, \n",
    "        epochs=100, \n",
    "        batch_size=32,\n",
    "        validation_split=0.1, \n",
    "        verbose=1,\n",
    "        callbacks=[reduce_lr]  \n",
    "    )\n",
    "\n",
    "    # history = model.fit(X_train, y_train, epochs=50, batch_size=32,validation_split=0.1, verbose=1) \n",
    "    \n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')\n",
    "    acc.append(score[1])\n",
    "    \n",
    "    test_predictions = model.predict(X_test)\n",
    "    test_label = to_categorical(y_test,3)\n",
    "\n",
    "    true_label= np.argmax(test_label, axis =1)\n",
    "\n",
    "    predicted_label= np.argmax(test_predictions, axis =1)\n",
    "    \n",
    "    cr = classification_report(true_label, predicted_label, output_dict=True)\n",
    "    precision.append(cr[\"macro avg\"][\"precision\"])\n",
    "    recall.append(cr[\"macro avg\"][\"recall\"])\n",
    "    f1.append(cr[\"macro avg\"][\"f1-score\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg accuracy: 0.47956404089927673\n",
      "Avg precision: 0.4103345594675074\n",
      "Avg recall: 0.3411717681380602\n",
      "Avg f1: 0.26167885841268396\n",
      "Std accuracy: 0.0\n",
      "Std precision: 0.0\n",
      "Std recall: 0.0\n",
      "Std f1: 0.0\n",
      "[0.47956404089927673]\n",
      "[0.4103345594675074]\n",
      "[0.3411717681380602]\n",
      "[0.26167885841268396]\n"
     ]
    }
   ],
   "source": [
    "print(\"Avg accuracy: \" + str(np.array(acc).mean()))\n",
    "print(\"Avg precision: \" + str(np.array(precision).mean()))\n",
    "print(\"Avg recall: \" + str(np.array(recall).mean()))\n",
    "print(\"Avg f1: \" + str(np.array(f1).mean()))\n",
    "print(\"Std accuracy: \" + str(np.array(acc).std()))\n",
    "print(\"Std precision: \" + str(np.array(precision).std()))\n",
    "print(\"Std recall: \" + str(np.array(recall).std()))\n",
    "print(\"Std f1: \" + str(np.array(f1).std()))\n",
    "print(acc)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_44 (Conv2D)          (None, 72, 72, 100)       2800      \n",
      "                                                                 \n",
      " batch_normalization_16 (Ba  (None, 72, 72, 100)       400       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation (Activation)     (None, 72, 72, 100)       0         \n",
      "                                                                 \n",
      " max_pooling2d_44 (MaxPooli  (None, 36, 36, 100)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_48 (Dropout)        (None, 36, 36, 100)       0         \n",
      "                                                                 \n",
      " conv2d_45 (Conv2D)          (None, 36, 36, 100)       90100     \n",
      "                                                                 \n",
      " batch_normalization_17 (Ba  (None, 36, 36, 100)       400       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 36, 36, 100)       0         \n",
      "                                                                 \n",
      " max_pooling2d_45 (MaxPooli  (None, 18, 18, 100)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_49 (Dropout)        (None, 18, 18, 100)       0         \n",
      "                                                                 \n",
      " conv2d_46 (Conv2D)          (None, 18, 18, 64)        57664     \n",
      "                                                                 \n",
      " batch_normalization_18 (Ba  (None, 18, 18, 64)        256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 18, 18, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_46 (MaxPooli  (None, 9, 9, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_50 (Dropout)        (None, 9, 9, 64)          0         \n",
      "                                                                 \n",
      " flatten_20 (Flatten)        (None, 5184)              0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 128)               663680    \n",
      "                                                                 \n",
      " batch_normalization_19 (Ba  (None, 128)               512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_51 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 816199 (3.11 MB)\n",
      "Trainable params: 815415 (3.11 MB)\n",
      "Non-trainable params: 784 (3.06 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "11/11 [==============================] - 7s 504ms/step - loss: 6.1104 - sparse_categorical_accuracy: 0.2977 - val_loss: 8.3795 - val_sparse_categorical_accuracy: 0.2368 - lr: 2.0000e-04\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 5s 433ms/step - loss: 5.8618 - sparse_categorical_accuracy: 0.3642 - val_loss: 6.1006 - val_sparse_categorical_accuracy: 0.3684 - lr: 4.0000e-04\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 5s 442ms/step - loss: 5.8544 - sparse_categorical_accuracy: 0.3815 - val_loss: 5.3802 - val_sparse_categorical_accuracy: 0.5263 - lr: 6.0000e-04\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 4s 399ms/step - loss: 5.6896 - sparse_categorical_accuracy: 0.3786 - val_loss: 6.1496 - val_sparse_categorical_accuracy: 0.2105 - lr: 8.0000e-04\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 4s 398ms/step - loss: 5.3734 - sparse_categorical_accuracy: 0.3815 - val_loss: 6.2241 - val_sparse_categorical_accuracy: 0.2632 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 4s 397ms/step - loss: 5.2225 - sparse_categorical_accuracy: 0.4162 - val_loss: 5.7214 - val_sparse_categorical_accuracy: 0.2368 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 5s 479ms/step - loss: 5.2256 - sparse_categorical_accuracy: 0.3960 - val_loss: 5.7395 - val_sparse_categorical_accuracy: 0.2105 - lr: 9.9973e-04\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 4s 399ms/step - loss: 4.9805 - sparse_categorical_accuracy: 0.4249 - val_loss: 5.2010 - val_sparse_categorical_accuracy: 0.3158 - lr: 9.9891e-04\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 5s 400ms/step - loss: 4.8445 - sparse_categorical_accuracy: 0.4422 - val_loss: 4.8271 - val_sparse_categorical_accuracy: 0.3684 - lr: 9.9754e-04\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 4s 389ms/step - loss: 4.7752 - sparse_categorical_accuracy: 0.4422 - val_loss: 4.6335 - val_sparse_categorical_accuracy: 0.5000 - lr: 9.9564e-04\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 4s 391ms/step - loss: 4.6072 - sparse_categorical_accuracy: 0.4624 - val_loss: 4.3023 - val_sparse_categorical_accuracy: 0.5789 - lr: 9.9319e-04\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 5s 414ms/step - loss: 4.5006 - sparse_categorical_accuracy: 0.4191 - val_loss: 4.1369 - val_sparse_categorical_accuracy: 0.6316 - lr: 9.9020e-04\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 5s 415ms/step - loss: 4.4070 - sparse_categorical_accuracy: 0.4451 - val_loss: 4.2059 - val_sparse_categorical_accuracy: 0.5000 - lr: 9.8668e-04\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 4s 401ms/step - loss: 4.1899 - sparse_categorical_accuracy: 0.4653 - val_loss: 4.1275 - val_sparse_categorical_accuracy: 0.5526 - lr: 9.8262e-04\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 4s 393ms/step - loss: 4.1054 - sparse_categorical_accuracy: 0.5116 - val_loss: 3.9652 - val_sparse_categorical_accuracy: 0.4737 - lr: 9.7804e-04\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 7s 669ms/step - loss: 4.0219 - sparse_categorical_accuracy: 0.4855 - val_loss: 3.9458 - val_sparse_categorical_accuracy: 0.4737 - lr: 9.7294e-04\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 5s 437ms/step - loss: 3.8413 - sparse_categorical_accuracy: 0.5058 - val_loss: 3.7949 - val_sparse_categorical_accuracy: 0.5526 - lr: 9.6731e-04\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 4s 396ms/step - loss: 3.8641 - sparse_categorical_accuracy: 0.4653 - val_loss: 3.7837 - val_sparse_categorical_accuracy: 0.4737 - lr: 9.6118e-04\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 5s 426ms/step - loss: 3.7370 - sparse_categorical_accuracy: 0.4769 - val_loss: 3.6566 - val_sparse_categorical_accuracy: 0.5263 - lr: 9.5455e-04\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 4s 398ms/step - loss: 3.7196 - sparse_categorical_accuracy: 0.4595 - val_loss: 3.5739 - val_sparse_categorical_accuracy: 0.4737 - lr: 9.4742e-04\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 4s 393ms/step - loss: 3.5547 - sparse_categorical_accuracy: 0.4798 - val_loss: 3.9173 - val_sparse_categorical_accuracy: 0.4211 - lr: 9.3980e-04\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 5s 441ms/step - loss: 3.4712 - sparse_categorical_accuracy: 0.5116 - val_loss: 3.4521 - val_sparse_categorical_accuracy: 0.5263 - lr: 9.3170e-04\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 5s 423ms/step - loss: 3.3427 - sparse_categorical_accuracy: 0.5058 - val_loss: 3.3332 - val_sparse_categorical_accuracy: 0.5526 - lr: 9.2312e-04\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 5s 437ms/step - loss: 3.3453 - sparse_categorical_accuracy: 0.4624 - val_loss: 3.3667 - val_sparse_categorical_accuracy: 0.5000 - lr: 9.1409e-04\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 5s 417ms/step - loss: 3.2675 - sparse_categorical_accuracy: 0.5116 - val_loss: 3.2301 - val_sparse_categorical_accuracy: 0.5526 - lr: 9.0460e-04\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 5s 430ms/step - loss: 3.1782 - sparse_categorical_accuracy: 0.4855 - val_loss: 3.1294 - val_sparse_categorical_accuracy: 0.5000 - lr: 8.9468e-04\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 5s 412ms/step - loss: 3.1229 - sparse_categorical_accuracy: 0.4624 - val_loss: 3.0617 - val_sparse_categorical_accuracy: 0.5263 - lr: 8.8432e-04\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 8s 736ms/step - loss: 3.0115 - sparse_categorical_accuracy: 0.5549 - val_loss: 2.9660 - val_sparse_categorical_accuracy: 0.5526 - lr: 8.7354e-04\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 6s 579ms/step - loss: 2.9659 - sparse_categorical_accuracy: 0.4827 - val_loss: 2.9896 - val_sparse_categorical_accuracy: 0.5526 - lr: 8.6235e-04\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 6s 523ms/step - loss: 2.9832 - sparse_categorical_accuracy: 0.4624 - val_loss: 2.9269 - val_sparse_categorical_accuracy: 0.5526 - lr: 8.5077e-04\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 5s 497ms/step - loss: 2.8456 - sparse_categorical_accuracy: 0.4942 - val_loss: 2.8464 - val_sparse_categorical_accuracy: 0.5263 - lr: 8.3880e-04\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 4s 372ms/step - loss: 2.8304 - sparse_categorical_accuracy: 0.4913 - val_loss: 2.8360 - val_sparse_categorical_accuracy: 0.5789 - lr: 8.2647e-04\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 5s 431ms/step - loss: 2.7883 - sparse_categorical_accuracy: 0.4884 - val_loss: 2.7563 - val_sparse_categorical_accuracy: 0.5789 - lr: 8.1377e-04\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 4s 369ms/step - loss: 2.7363 - sparse_categorical_accuracy: 0.5231 - val_loss: 2.6954 - val_sparse_categorical_accuracy: 0.5526 - lr: 8.0074e-04\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 5s 418ms/step - loss: 2.7017 - sparse_categorical_accuracy: 0.4827 - val_loss: 2.6242 - val_sparse_categorical_accuracy: 0.5526 - lr: 7.8738e-04\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 4s 386ms/step - loss: 2.6518 - sparse_categorical_accuracy: 0.5087 - val_loss: 2.5978 - val_sparse_categorical_accuracy: 0.5526 - lr: 7.7370e-04\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 4s 368ms/step - loss: 2.5863 - sparse_categorical_accuracy: 0.4971 - val_loss: 2.5830 - val_sparse_categorical_accuracy: 0.5000 - lr: 7.5973e-04\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 4s 377ms/step - loss: 2.4966 - sparse_categorical_accuracy: 0.5434 - val_loss: 2.5395 - val_sparse_categorical_accuracy: 0.5526 - lr: 7.4547e-04\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 4s 369ms/step - loss: 2.5726 - sparse_categorical_accuracy: 0.4566 - val_loss: 2.4960 - val_sparse_categorical_accuracy: 0.5000 - lr: 7.3094e-04\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 7s 704ms/step - loss: 2.4860 - sparse_categorical_accuracy: 0.4971 - val_loss: 2.4559 - val_sparse_categorical_accuracy: 0.5263 - lr: 7.1616e-04\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 5s 404ms/step - loss: 2.3953 - sparse_categorical_accuracy: 0.5318 - val_loss: 2.4096 - val_sparse_categorical_accuracy: 0.6053 - lr: 7.0115e-04\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 4s 404ms/step - loss: 2.4323 - sparse_categorical_accuracy: 0.4971 - val_loss: 2.4059 - val_sparse_categorical_accuracy: 0.4737 - lr: 6.8591e-04\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 6s 538ms/step - loss: 2.3780 - sparse_categorical_accuracy: 0.5289 - val_loss: 2.3109 - val_sparse_categorical_accuracy: 0.5526 - lr: 6.7048e-04\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 5s 454ms/step - loss: 2.2895 - sparse_categorical_accuracy: 0.5434 - val_loss: 2.2881 - val_sparse_categorical_accuracy: 0.5526 - lr: 6.5485e-04\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 10s 922ms/step - loss: 2.3055 - sparse_categorical_accuracy: 0.5260 - val_loss: 2.2712 - val_sparse_categorical_accuracy: 0.5526 - lr: 6.3906e-04\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 7s 611ms/step - loss: 2.2750 - sparse_categorical_accuracy: 0.4711 - val_loss: 2.2501 - val_sparse_categorical_accuracy: 0.5526 - lr: 6.2312e-04\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 5s 471ms/step - loss: 2.2134 - sparse_categorical_accuracy: 0.5434 - val_loss: 2.2620 - val_sparse_categorical_accuracy: 0.5526 - lr: 6.0704e-04\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 10s 893ms/step - loss: 2.2091 - sparse_categorical_accuracy: 0.4942 - val_loss: 2.2078 - val_sparse_categorical_accuracy: 0.5526 - lr: 5.9085e-04\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 7s 610ms/step - loss: 2.1333 - sparse_categorical_accuracy: 0.5260 - val_loss: 2.1764 - val_sparse_categorical_accuracy: 0.5526 - lr: 5.7456e-04\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 5s 460ms/step - loss: 2.1467 - sparse_categorical_accuracy: 0.5231 - val_loss: 2.1575 - val_sparse_categorical_accuracy: 0.5526 - lr: 5.5818e-04\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 5s 451ms/step - loss: 2.0987 - sparse_categorical_accuracy: 0.5578 - val_loss: 2.1582 - val_sparse_categorical_accuracy: 0.6053 - lr: 5.4175e-04\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 5s 456ms/step - loss: 2.1036 - sparse_categorical_accuracy: 0.5173 - val_loss: 2.1305 - val_sparse_categorical_accuracy: 0.5789 - lr: 5.2527e-04\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 5s 435ms/step - loss: 2.0548 - sparse_categorical_accuracy: 0.5665 - val_loss: 2.0886 - val_sparse_categorical_accuracy: 0.6316 - lr: 5.0876e-04\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 5s 445ms/step - loss: 2.0697 - sparse_categorical_accuracy: 0.5173 - val_loss: 2.1113 - val_sparse_categorical_accuracy: 0.6053 - lr: 4.9224e-04\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 5s 442ms/step - loss: 2.0607 - sparse_categorical_accuracy: 0.4827 - val_loss: 2.0526 - val_sparse_categorical_accuracy: 0.6053 - lr: 4.7573e-04\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 5s 465ms/step - loss: 2.0227 - sparse_categorical_accuracy: 0.5260 - val_loss: 2.0442 - val_sparse_categorical_accuracy: 0.6053 - lr: 4.5925e-04\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 6s 601ms/step - loss: 1.9794 - sparse_categorical_accuracy: 0.5491 - val_loss: 2.0377 - val_sparse_categorical_accuracy: 0.6053 - lr: 4.4282e-04\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 7s 612ms/step - loss: 1.9811 - sparse_categorical_accuracy: 0.5173 - val_loss: 2.0179 - val_sparse_categorical_accuracy: 0.5789 - lr: 4.2644e-04\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 5s 459ms/step - loss: 1.9626 - sparse_categorical_accuracy: 0.5202 - val_loss: 1.9961 - val_sparse_categorical_accuracy: 0.5789 - lr: 4.1015e-04\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 6s 517ms/step - loss: 1.9426 - sparse_categorical_accuracy: 0.5347 - val_loss: 1.9992 - val_sparse_categorical_accuracy: 0.5789 - lr: 3.9396e-04\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 5s 406ms/step - loss: 1.9031 - sparse_categorical_accuracy: 0.5694 - val_loss: 2.0110 - val_sparse_categorical_accuracy: 0.5789 - lr: 3.7788e-04\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 4s 406ms/step - loss: 1.9559 - sparse_categorical_accuracy: 0.5347 - val_loss: 1.9397 - val_sparse_categorical_accuracy: 0.6053 - lr: 3.6194e-04\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 5s 437ms/step - loss: 1.8943 - sparse_categorical_accuracy: 0.4913 - val_loss: 1.9718 - val_sparse_categorical_accuracy: 0.6316 - lr: 3.4615e-04\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 5s 450ms/step - loss: 1.9204 - sparse_categorical_accuracy: 0.5347 - val_loss: 1.9802 - val_sparse_categorical_accuracy: 0.5789 - lr: 3.3052e-04\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 5s 441ms/step - loss: 1.8218 - sparse_categorical_accuracy: 0.5578 - val_loss: 1.9147 - val_sparse_categorical_accuracy: 0.6053 - lr: 3.1509e-04\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 5s 420ms/step - loss: 1.8189 - sparse_categorical_accuracy: 0.5578 - val_loss: 1.9299 - val_sparse_categorical_accuracy: 0.5789 - lr: 2.9985e-04\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 5s 448ms/step - loss: 1.8531 - sparse_categorical_accuracy: 0.5318 - val_loss: 1.9071 - val_sparse_categorical_accuracy: 0.5789 - lr: 2.8484e-04\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 5s 430ms/step - loss: 1.8430 - sparse_categorical_accuracy: 0.5607 - val_loss: 1.8768 - val_sparse_categorical_accuracy: 0.6053 - lr: 2.7006e-04\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 5s 415ms/step - loss: 1.8329 - sparse_categorical_accuracy: 0.5145 - val_loss: 1.8362 - val_sparse_categorical_accuracy: 0.5526 - lr: 2.5553e-04\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 5s 410ms/step - loss: 1.8432 - sparse_categorical_accuracy: 0.5347 - val_loss: 1.8420 - val_sparse_categorical_accuracy: 0.5526 - lr: 2.4127e-04\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 6s 558ms/step - loss: 1.8040 - sparse_categorical_accuracy: 0.5260 - val_loss: 1.8715 - val_sparse_categorical_accuracy: 0.5789 - lr: 2.2730e-04\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 5s 425ms/step - loss: 1.7836 - sparse_categorical_accuracy: 0.5405 - val_loss: 1.8613 - val_sparse_categorical_accuracy: 0.6316 - lr: 2.1362e-04\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 5s 411ms/step - loss: 1.7955 - sparse_categorical_accuracy: 0.5636 - val_loss: 1.8511 - val_sparse_categorical_accuracy: 0.4737 - lr: 2.0026e-04\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 4s 410ms/step - loss: 1.7977 - sparse_categorical_accuracy: 0.5289 - val_loss: 1.8434 - val_sparse_categorical_accuracy: 0.5789 - lr: 1.8723e-04\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 5s 415ms/step - loss: 1.7562 - sparse_categorical_accuracy: 0.5665 - val_loss: 1.7733 - val_sparse_categorical_accuracy: 0.6316 - lr: 1.7453e-04\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 4s 401ms/step - loss: 1.7943 - sparse_categorical_accuracy: 0.5029 - val_loss: 1.7727 - val_sparse_categorical_accuracy: 0.5789 - lr: 1.6220e-04\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 5s 415ms/step - loss: 1.7742 - sparse_categorical_accuracy: 0.5520 - val_loss: 1.7972 - val_sparse_categorical_accuracy: 0.6316 - lr: 1.5023e-04\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 5s 408ms/step - loss: 1.7714 - sparse_categorical_accuracy: 0.4913 - val_loss: 1.8139 - val_sparse_categorical_accuracy: 0.5526 - lr: 1.3865e-04\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 5s 434ms/step - loss: 1.7496 - sparse_categorical_accuracy: 0.5549 - val_loss: 1.7536 - val_sparse_categorical_accuracy: 0.5789 - lr: 1.2746e-04\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 4s 403ms/step - loss: 1.7395 - sparse_categorical_accuracy: 0.5318 - val_loss: 1.7682 - val_sparse_categorical_accuracy: 0.5789 - lr: 1.1668e-04\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 4s 402ms/step - loss: 1.7747 - sparse_categorical_accuracy: 0.5087 - val_loss: 1.7998 - val_sparse_categorical_accuracy: 0.5789 - lr: 1.0632e-04\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 4s 403ms/step - loss: 1.7945 - sparse_categorical_accuracy: 0.5145 - val_loss: 1.7961 - val_sparse_categorical_accuracy: 0.6053 - lr: 9.6396e-05\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 4s 402ms/step - loss: 1.7974 - sparse_categorical_accuracy: 0.5231 - val_loss: 1.7835 - val_sparse_categorical_accuracy: 0.5789 - lr: 8.6910e-05\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 6s 582ms/step - loss: 1.7648 - sparse_categorical_accuracy: 0.5491 - val_loss: 1.7582 - val_sparse_categorical_accuracy: 0.6316 - lr: 7.7875e-05\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 8s 736ms/step - loss: 1.7507 - sparse_categorical_accuracy: 0.5260 - val_loss: 1.7764 - val_sparse_categorical_accuracy: 0.6053 - lr: 6.9303e-05\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 6s 561ms/step - loss: 1.6895 - sparse_categorical_accuracy: 0.5809 - val_loss: 1.7334 - val_sparse_categorical_accuracy: 0.6316 - lr: 6.1203e-05\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 6s 495ms/step - loss: 1.7036 - sparse_categorical_accuracy: 0.5607 - val_loss: 1.7347 - val_sparse_categorical_accuracy: 0.5789 - lr: 5.3583e-05\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 6s 550ms/step - loss: 1.7157 - sparse_categorical_accuracy: 0.5491 - val_loss: 1.7243 - val_sparse_categorical_accuracy: 0.6053 - lr: 4.6451e-05\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 6s 550ms/step - loss: 1.7217 - sparse_categorical_accuracy: 0.5202 - val_loss: 1.7455 - val_sparse_categorical_accuracy: 0.5789 - lr: 3.9816e-05\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 5s 462ms/step - loss: 1.6859 - sparse_categorical_accuracy: 0.5665 - val_loss: 1.7386 - val_sparse_categorical_accuracy: 0.5789 - lr: 3.3685e-05\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 5s 460ms/step - loss: 1.7038 - sparse_categorical_accuracy: 0.5636 - val_loss: 1.7203 - val_sparse_categorical_accuracy: 0.5789 - lr: 2.8064e-05\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 5s 467ms/step - loss: 1.7399 - sparse_categorical_accuracy: 0.4971 - val_loss: 1.7207 - val_sparse_categorical_accuracy: 0.6053 - lr: 2.2960e-05\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 5s 499ms/step - loss: 1.7289 - sparse_categorical_accuracy: 0.5173 - val_loss: 1.7254 - val_sparse_categorical_accuracy: 0.6053 - lr: 1.8378e-05\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 7s 595ms/step - loss: 1.7568 - sparse_categorical_accuracy: 0.5260 - val_loss: 1.7664 - val_sparse_categorical_accuracy: 0.5526 - lr: 1.4323e-05\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 8s 754ms/step - loss: 1.6692 - sparse_categorical_accuracy: 0.5751 - val_loss: 1.7446 - val_sparse_categorical_accuracy: 0.6316 - lr: 1.0800e-05\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 7s 619ms/step - loss: 1.7173 - sparse_categorical_accuracy: 0.5607 - val_loss: 1.7375 - val_sparse_categorical_accuracy: 0.5789 - lr: 7.8125e-06\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 6s 424ms/step - loss: 1.7249 - sparse_categorical_accuracy: 0.5202 - val_loss: 1.7403 - val_sparse_categorical_accuracy: 0.5789 - lr: 5.3636e-06\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 5s 410ms/step - loss: 1.7019 - sparse_categorical_accuracy: 0.5491 - val_loss: 1.7559 - val_sparse_categorical_accuracy: 0.5789 - lr: 3.4561e-06\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - ETA: 0s - loss: 1.6885 - sparse_categorical_accuracy: 0.5491\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 1.0460465773576288e-06.\n",
      "11/11 [==============================] - 5s 439ms/step - loss: 1.6885 - sparse_categorical_accuracy: 0.5491 - val_loss: 1.7287 - val_sparse_categorical_accuracy: 0.5526 - lr: 2.0921e-06\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 5s 419ms/step - loss: 1.6882 - sparse_categorical_accuracy: 0.5145 - val_loss: 1.7580 - val_sparse_categorical_accuracy: 0.6316 - lr: 1.2731e-06\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.6208 - sparse_categorical_accuracy: 0.6905\n",
      "Test loss: 1.6207823753356934 / Test accuracy: 0.6904761791229248\n",
      "WARNING:tensorflow:5 out of the last 19 calls to <function Model.make_predict_function.<locals>.predict_function at 0x11023c040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 19 calls to <function Model.make_predict_function.<locals>.predict_function at 0x11023c040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 21ms/step\n",
      "\n",
      "Classification Report:\n",
      "Precision: 0.5524\n",
      "Recall: 0.5333\n",
      "F1-score: 0.5144\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, LearningRateScheduler\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import math\n",
    "\n",
    "# 1. Setup data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "   rotation_range=15,\n",
    "   width_shift_range=0.15,\n",
    "   height_shift_range=0.15,\n",
    "   horizontal_flip=True,\n",
    "   vertical_flip=False,\n",
    "   fill_mode='nearest',\n",
    "   zoom_range=0.1,\n",
    "   brightness_range=[0.9,1.1],\n",
    "   validation_split=0.1\n",
    ")\n",
    "\n",
    "# 2. Create the enhanced model\n",
    "model = Sequential([\n",
    "   # First Block\n",
    "   Conv2D(100, (3, 3), padding='same', kernel_regularizer=l2(0.01), input_shape=(72, 72, 3)),\n",
    "   BatchNormalization(),\n",
    "   Activation('relu'),\n",
    "   MaxPooling2D((2, 2)),\n",
    "   Dropout(0.3),\n",
    "   \n",
    "   # Second Block\n",
    "   Conv2D(100, (3, 3), padding='same', kernel_regularizer=l2(0.01)),\n",
    "   BatchNormalization(),\n",
    "   Activation('relu'),\n",
    "   MaxPooling2D((2, 2)),\n",
    "   Dropout(0.3),\n",
    "   \n",
    "   # Third Block\n",
    "   Conv2D(64, (3, 3), padding='same', kernel_regularizer=l2(0.01)),\n",
    "   BatchNormalization(),\n",
    "   Activation('relu'),\n",
    "   MaxPooling2D((2, 2)),\n",
    "   Dropout(0.3),\n",
    "   \n",
    "   # Dense Layers\n",
    "   Flatten(),\n",
    "   Dense(128, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "   BatchNormalization(),\n",
    "   Dropout(0.5),\n",
    "   Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# 3. Learning rate scheduler with warmup and cosine decay\n",
    "def cosine_decay_with_warmup(epoch, total_epochs, warmup_epochs, base_lr, min_lr):\n",
    "   if epoch < warmup_epochs:\n",
    "       return base_lr * (epoch + 1) / warmup_epochs\n",
    "   \n",
    "   progress = (epoch - warmup_epochs) / (total_epochs - warmup_epochs)\n",
    "   return min_lr + 0.5 * (base_lr - min_lr) * (1 + math.cos(math.pi * progress))\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(\n",
    "   lambda epoch: cosine_decay_with_warmup(\n",
    "       epoch, \n",
    "       total_epochs=100, \n",
    "       warmup_epochs=5,\n",
    "       base_lr=0.001,\n",
    "       min_lr=1e-6\n",
    "   )\n",
    ")\n",
    "\n",
    "# 4. Reduce learning rate plateau\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "   monitor='val_loss',\n",
    "   factor=0.5,\n",
    "   patience=8,\n",
    "   min_lr=1e-6,\n",
    "   verbose=1\n",
    ")\n",
    "\n",
    "# 5. Compile model\n",
    "model.compile(\n",
    "   optimizer=Adam(\n",
    "       learning_rate=0.001,\n",
    "       beta_1=0.9,\n",
    "       beta_2=0.999,\n",
    "       epsilon=1e-07,\n",
    "       amsgrad=True\n",
    "   ),\n",
    "   loss='sparse_categorical_crossentropy',\n",
    "   metrics=['sparse_categorical_accuracy']\n",
    ")\n",
    "\n",
    "# 6. Print model summary\n",
    "model.summary()\n",
    "\n",
    "# 7. Create data generators\n",
    "train_generator = datagen.flow(\n",
    "   X_train, y_train,\n",
    "   batch_size=32,\n",
    "   subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow(\n",
    "   X_train, y_train,\n",
    "   batch_size=32,\n",
    "   subset='validation'\n",
    ")\n",
    "\n",
    "# 8. Train the model\n",
    "history = model.fit(\n",
    "   train_generator,\n",
    "   epochs=100,\n",
    "   validation_data=validation_generator,\n",
    "   callbacks=[lr_scheduler, reduce_lr],\n",
    "   verbose=1\n",
    ")\n",
    "\n",
    "# 9. Evaluate model\n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')\n",
    "\n",
    "# 10. Generate predictions and metrics\n",
    "test_predictions = model.predict(X_test)\n",
    "test_label = to_categorical(y_test, 3)\n",
    "true_label = np.argmax(test_label, axis=1)\n",
    "predicted_label = np.argmax(test_predictions, axis=1)\n",
    "\n",
    "# 11. Calculate classification metrics\n",
    "cr = classification_report(true_label, predicted_label, output_dict=True)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(f\"Precision: {cr['macro avg']['precision']:.4f}\")\n",
    "print(f\"Recall: {cr['macro avg']['recall']:.4f}\")\n",
    "print(f\"F1-score: {cr['macro avg']['f1-score']:.4f}\")\n",
    "\n",
    "# Store metrics if needed\n",
    "precision.append(cr[\"macro avg\"][\"precision\"])\n",
    "recall.append(cr[\"macro avg\"][\"recall\"])\n",
    "f1.append(cr[\"macro avg\"][\"f1-score\"])\n",
    "acc.append(score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_31 (Conv2D)          (None, 72, 72, 128)       3584      \n",
      "                                                                 \n",
      " batch_normalization_12 (Ba  (None, 72, 72, 128)       512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_31 (MaxPooli  (None, 36, 36, 128)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_34 (Dropout)        (None, 36, 36, 128)       0         \n",
      "                                                                 \n",
      " conv2d_32 (Conv2D)          (None, 36, 36, 64)        73792     \n",
      "                                                                 \n",
      " batch_normalization_13 (Ba  (None, 36, 36, 64)        256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_32 (MaxPooli  (None, 18, 18, 64)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 18, 18, 64)        0         \n",
      "                                                                 \n",
      " conv2d_33 (Conv2D)          (None, 18, 18, 32)        18464     \n",
      "                                                                 \n",
      " batch_normalization_14 (Ba  (None, 18, 18, 32)        128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_33 (MaxPooli  (None, 9, 9, 32)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 9, 9, 32)          0         \n",
      "                                                                 \n",
      " flatten_14 (Flatten)        (None, 2592)              0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 128)               331904    \n",
      "                                                                 \n",
      " batch_normalization_15 (Ba  (None, 128)               512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 429539 (1.64 MB)\n",
      "Trainable params: 428835 (1.64 MB)\n",
      "Non-trainable params: 704 (2.75 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "11/11 [==============================] - 7s 515ms/step - loss: 1.6808 - sparse_categorical_accuracy: 0.3728 - val_loss: 1.3599 - val_sparse_categorical_accuracy: 0.3684 - lr: 5.0000e-05\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 4s 391ms/step - loss: 1.6998 - sparse_categorical_accuracy: 0.3671 - val_loss: 1.2943 - val_sparse_categorical_accuracy: 0.3421 - lr: 5.0000e-05\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 4s 386ms/step - loss: 1.7560 - sparse_categorical_accuracy: 0.3295 - val_loss: 1.3048 - val_sparse_categorical_accuracy: 0.2895 - lr: 5.0000e-05\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 4s 358ms/step - loss: 1.7610 - sparse_categorical_accuracy: 0.3208 - val_loss: 1.2150 - val_sparse_categorical_accuracy: 0.4211 - lr: 5.0000e-05\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 4s 382ms/step - loss: 1.7655 - sparse_categorical_accuracy: 0.3410 - val_loss: 1.2093 - val_sparse_categorical_accuracy: 0.2895 - lr: 5.0000e-05\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 5s 431ms/step - loss: 1.5928 - sparse_categorical_accuracy: 0.3555 - val_loss: 1.3350 - val_sparse_categorical_accuracy: 0.3421 - lr: 5.0000e-05\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 5s 432ms/step - loss: 1.7494 - sparse_categorical_accuracy: 0.3237 - val_loss: 1.0724 - val_sparse_categorical_accuracy: 0.3421 - lr: 5.0000e-05\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 5s 444ms/step - loss: 1.5874 - sparse_categorical_accuracy: 0.3960 - val_loss: 1.1661 - val_sparse_categorical_accuracy: 0.2632 - lr: 5.0000e-05\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 5s 454ms/step - loss: 1.5059 - sparse_categorical_accuracy: 0.3931 - val_loss: 1.1489 - val_sparse_categorical_accuracy: 0.3158 - lr: 5.0000e-05\n",
      "Epoch 10/100\n",
      " 8/11 [====================>.........] - ETA: 2s - loss: 1.9105 - sparse_categorical_accuracy: 0.3477"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-3faa8f2d6889>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;31m# 8. Train model with augmented data and callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     84\u001b[0m    \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m    \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/idls24/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/idls24/lib/python3.8/site-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1740\u001b[0m                         ):\n\u001b[1;32m   1741\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1742\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1743\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1744\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/idls24/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/idls24/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/idls24/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    855\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/idls24/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m       (concrete_function,\n\u001b[1;32m    147\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    149\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/idls24/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1347\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1348\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1349\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_call_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1350\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/idls24/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/idls24/lib/python3.8/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1457\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1458\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/idls24/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# 1. Set up data augmentation to increase training data diversity\n",
    "datagen = ImageDataGenerator(\n",
    "   rotation_range=10,\n",
    "   width_shift_range=0.1,\n",
    "   height_shift_range=0.1,\n",
    "   horizontal_flip=True,\n",
    "   fill_mode='nearest',\n",
    "   validation_split=0.1  # Split ratio for validation set\n",
    ")\n",
    "\n",
    "# 2. Calculate class weights to handle class imbalance\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "# 3. Build enhanced model architecture\n",
    "model = Sequential([\n",
    "   # First Convolutional Block\n",
    "   Conv2D(128, (3, 3), activation='relu', padding='same', input_shape=(72, 72, 3)),\n",
    "   BatchNormalization(),  # Normalize activations for better training stability\n",
    "   MaxPooling2D((2, 2)),\n",
    "   Dropout(0.3),  # Prevent overfitting\n",
    "   \n",
    "   # Second Convolutional Block\n",
    "   Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "   BatchNormalization(),\n",
    "   MaxPooling2D((2, 2)),\n",
    "   Dropout(0.3),\n",
    "   \n",
    "   # Third Convolutional Block\n",
    "   Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "   BatchNormalization(),\n",
    "   MaxPooling2D((2, 2)),\n",
    "   Dropout(0.3),\n",
    "   \n",
    "   # Fully Connected Layers\n",
    "   Flatten(),  # Convert 3D feature maps to 1D vector\n",
    "   Dense(128, activation='relu'),  # Additional capacity for learning\n",
    "   BatchNormalization(),\n",
    "   Dropout(0.5),\n",
    "   Dense(3, activation='softmax')  # Output layer for 3 classes\n",
    "])\n",
    "\n",
    "# 4. Setup learning rate scheduler for adaptive learning rate\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "   monitor='val_loss',  # Monitor validation loss\n",
    "   factor=0.5,         # Multiply learning rate by 0.5 when plateauing\n",
    "   patience=10,        # Number of epochs to wait before reducing LR\n",
    "   min_lr=1e-10,       # Minimum learning rate\n",
    "   verbose=1          # Print message when reducing LR\n",
    ")\n",
    "\n",
    "# 5. Compile model with optimizer and loss function\n",
    "model.compile(\n",
    "   optimizer=Adam(learning_rate=0.00005),\n",
    "   loss='sparse_categorical_crossentropy',\n",
    "   metrics=['sparse_categorical_accuracy']\n",
    ")\n",
    "\n",
    "# 6. Display model architecture\n",
    "model.summary()\n",
    "\n",
    "# 7. Create data generators for training and validation\n",
    "train_generator = datagen.flow(\n",
    "   X_train, y_train,\n",
    "   batch_size=32,\n",
    "   subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow(\n",
    "   X_train, y_train,\n",
    "   batch_size=32,\n",
    "   subset='validation'\n",
    ")\n",
    "\n",
    "# 8. Train model with augmented data and callbacks\n",
    "history = model.fit(\n",
    "   train_generator,\n",
    "   epochs=100,\n",
    "   validation_data=validation_generator,\n",
    "   class_weight=class_weight_dict,  # Apply class weights\n",
    "   callbacks=[reduce_lr]            # Use learning rate scheduler\n",
    ")\n",
    "\n",
    "# 9. Evaluate model performance on test set\n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')\n",
    "\n",
    "# 10. Generate predictions and detailed metrics\n",
    "test_predictions = model.predict(X_test)\n",
    "predicted_label = np.argmax(test_predictions, axis=1)\n",
    "test_label = to_categorical(y_test, 3)\n",
    "true_label = np.argmax(test_label, axis=1)\n",
    "\n",
    "# 11. Calculate and print classification metrics\n",
    "cr = classification_report(true_label, predicted_label, output_dict=True)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(f\"Precision: {cr['macro avg']['precision']:.4f}\")\n",
    "print(f\"Recall: {cr['macro avg']['recall']:.4f}\")\n",
    "print(f\"F1-score: {cr['macro avg']['f1-score']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idls24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
