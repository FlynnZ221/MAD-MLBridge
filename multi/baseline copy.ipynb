{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import gc, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.utils import compute_class_weight\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense, Dropout,Flatten, BatchNormalization, Conv2D, MultiHeadAttention, concatenate\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras.layers import Lambda\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_img(t_img):\n",
    "    img = pd.read_pickle(t_img)\n",
    "    img_l = []\n",
    "    for i in range(len(img)):\n",
    "        img_l.append(img.values[i][0])\n",
    "    \n",
    "    return np.array(img_l)\n",
    "\n",
    "\n",
    "def reset_random_seeds(seed):\n",
    "    os.environ['PYTHONHASHSEED']=str(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "   \n",
    "               \n",
    "def create_model_snp():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(200,  activation = \"relu\")) \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, activation = \"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Dense(50, activation = \"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    return model\n",
    "\n",
    "def create_model_clinical():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128,  activation = \"relu\")) \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128, activation = \"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(50, activation = \"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))    \n",
    "    return model\n",
    "\n",
    "def create_model_img():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(72, (3, 3), activation='relu')) \n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(50, activation='relu'))   \n",
    "    return model\n",
    "\n",
    "def plot_classification_report(y_tru, y_prd, mode, learning_rate, batch_size,epochs, figsize=(7, 7), ax=None):\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    xticks = ['precision', 'recall', 'f1-score', 'support']\n",
    "    yticks = [\"Control\", \"Moderate\", \"Alzheimer's\" ] \n",
    "    yticks += ['avg']\n",
    "\n",
    "    rep = np.array(precision_recall_fscore_support(y_tru, y_prd)).T\n",
    "    avg = np.mean(rep, axis=0)\n",
    "    avg[-1] = np.sum(rep[:, -1])\n",
    "    rep = np.insert(rep, rep.shape[0], avg, axis=0)\n",
    "\n",
    "    sns.heatmap(rep,\n",
    "                annot=True, \n",
    "                cbar=False, \n",
    "                xticklabels=xticks, \n",
    "                yticklabels=yticks,\n",
    "                ax=ax, cmap = \"Blues\")\n",
    "    \n",
    "    plt.savefig('report_' + str(mode) + '_' + str(learning_rate) +'_' + str(batch_size)+'_' + str(epochs)+'.png')\n",
    "    \n",
    "\n",
    "def calc_confusion_matrix(result, test_label,mode, learning_rate, batch_size, epochs):\n",
    "    test_label = to_categorical(test_label,3)\n",
    "\n",
    "    true_label= np.argmax(test_label, axis =1)\n",
    "\n",
    "    predicted_label= np.argmax(result, axis =1)\n",
    "    \n",
    "    n_classes = 3\n",
    "    precision = dict()\n",
    "    recall = dict()\n",
    "    thres = dict()\n",
    "    for i in range(n_classes):\n",
    "        precision[i], recall[i], thres[i] = precision_recall_curve(test_label[:, i],\n",
    "                                                            result[:, i])\n",
    "\n",
    "\n",
    "    print (\"Classification Report :\") \n",
    "    print (classification_report(true_label, predicted_label))\n",
    "    cr = classification_report(true_label, predicted_label, output_dict=True)\n",
    "    return cr, precision, recall, thres\n",
    "\n",
    "\n",
    "def cross_modal_attention(x, y):\n",
    "    x = tf.expand_dims(x, axis=1)\n",
    "    y = tf.expand_dims(y, axis=1)\n",
    "    a1 = MultiHeadAttention(num_heads = 4,key_dim=50)(x, y)\n",
    "    a2 = MultiHeadAttention(num_heads = 4,key_dim=50)(y, x)\n",
    "    a1 = a1[:,0,:]\n",
    "    a2 = a2[:,0,:]\n",
    "    return concatenate([a1, a2])\n",
    "\n",
    "\n",
    "def self_attention(x):\n",
    "    x = tf.expand_dims(x, axis=1)\n",
    "    attention = MultiHeadAttention(num_heads = 4, key_dim=50)(x, x)\n",
    "    attention = attention[:,0,:]\n",
    "    return attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clinical = pd.read_csv(\"../preprocess_overlap/X_train_clinical.csv\").values\n",
    "test_clinical= pd.read_csv(\"../preprocess_overlap/X_test_clinical.csv\").values\n",
    "\n",
    "train_snp = pd.read_csv(\"../preprocess_overlap/X_train_snp.csv\").values\n",
    "test_snp = pd.read_csv(\"../preprocess_overlap/X_test_snp.csv\").values\n",
    "\n",
    "train_img= make_img(\"../preprocess_overlap/X_train_img.pkl\")\n",
    "test_img= make_img(\"../preprocess_overlap/X_test_img.pkl\")\n",
    "\n",
    "train_label= pd.read_csv(\"../preprocess_overlap/y_train.csv\").values.astype(\"int\").flatten()\n",
    "test_label= pd.read_csv(\"../preprocess_overlap/y_test.csv\").values.astype(\"int\").flatten()\n",
    "\n",
    "train_clinical = train_clinical.astype(\"float32\")\n",
    "test_clinical = test_clinical.astype(\"float32\")\n",
    "# train_snp = train_snp.astype(\"float32\")\n",
    "# train_snp = test_snp.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "def multi_modal_model_baseline(mode, train_clinical, train_snp, train_img):\n",
    "    in_clinical = Input(shape=(train_clinical.shape[1]))\n",
    "    in_snp = Input(shape=(train_snp.shape[1]))\n",
    "    in_img = Input(shape=(train_img.shape[1], train_img.shape[2], train_img.shape[3]))\n",
    "    \n",
    "    dense_clinical = create_model_clinical()(in_clinical)\n",
    "    dense_snp = create_model_snp()(in_snp)\n",
    "    dense_img = create_model_img()(in_img)\n",
    "    \n",
    "    if mode == 'MM_BA':\n",
    "        vt_att = cross_modal_attention(dense_img, dense_clinical)\n",
    "        av_att = cross_modal_attention(dense_snp, dense_img)\n",
    "        ta_att = cross_modal_attention(dense_clinical, dense_snp)\n",
    "        merged = concatenate([vt_att, av_att, ta_att, dense_img, dense_snp, dense_clinical])\n",
    "    elif mode == 'MM_SA':\n",
    "        vv_att = self_attention(dense_img)\n",
    "        tt_att = self_attention(dense_clinical)\n",
    "        aa_att = self_attention(dense_snp)\n",
    "        merged = concatenate([aa_att, vv_att, tt_att, dense_img, dense_snp, dense_clinical])\n",
    "    elif mode == 'MM_SA_BA':\n",
    "        vv_att = self_attention(dense_img)\n",
    "        tt_att = self_attention(dense_clinical)\n",
    "        aa_att = self_attention(dense_snp)\n",
    "        vt_att = cross_modal_attention(vv_att, tt_att)\n",
    "        av_att = cross_modal_attention(aa_att, vv_att)\n",
    "        ta_att = cross_modal_attention(tt_att, aa_att)\n",
    "        merged = concatenate([vt_att, av_att, ta_att, dense_img, dense_snp, dense_clinical])\n",
    "    elif mode == 'None':\n",
    "        merged = concatenate([dense_img, dense_snp, dense_clinical])\n",
    "    else:\n",
    "        print(\"Invalid mode. Choose from 'MM_SA', 'MM_BA', 'MM_SA_BA', 'None'.\")\n",
    "        return\n",
    "    \n",
    "    features_model = Model(inputs=[in_clinical, in_snp, in_img], outputs=merged)\n",
    "    return features_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_baseline(mode, train_clinical, train_snp, train_img, train_label, test_clinical, test_snp, test_img, test_label):\n",
    "    feature_model = multi_modal_model_baseline(mode, train_clinical, train_snp, train_img)\n",
    "    train_features = feature_model.predict([train_clinical, train_snp, train_img])\n",
    "    test_features = feature_model.predict([test_clinical, test_snp, test_img])\n",
    "    \n",
    "    classifier = LogisticRegression(max_iter=1000)\n",
    "    classifier.fit(train_features, train_label)\n",
    "    predictions = classifier.predict(test_features)\n",
    "    \n",
    "    accuracy = accuracy_score(test_label, predictions)\n",
    "    print(\"Test Accuracy: \", accuracy)\n",
    "    print(classification_report(test_label, predictions))\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 450), dtype=tf.float32, name=None), name='concatenate_15/concat:0', description=\"created by layer 'concatenate_15'\")\n",
      "5/5 [==============================] - 1s 65ms/step\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "Test Accuracy:  0.9142857142857143\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94        24\n",
      "           1       0.67      0.50      0.57         4\n",
      "           2       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           0.91        35\n",
      "   macro avg       0.86      0.82      0.84        35\n",
      "weighted avg       0.91      0.91      0.91        35\n",
      "\n",
      "Baseline Model Accuracy: 0.9143\n"
     ]
    }
   ],
   "source": [
    "accuracy = train_baseline(\n",
    "    mode=\"MM_SA_BA\",\n",
    "    train_clinical=train_clinical,\n",
    "    train_snp=train_snp,\n",
    "    train_img=train_img,\n",
    "    train_label=train_label,\n",
    "    test_clinical=test_clinical,\n",
    "    test_snp=test_snp,\n",
    "    test_img=test_img,\n",
    "    test_label=test_label\n",
    ")\n",
    "print(f\"Baseline Model Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)        [(None, 72, 72, 3)]          0         []                            \n",
      "                                                                                                  \n",
      " input_1 (InputLayer)        [(None, 149)]                0         []                            \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, 179666)]             0         []                            \n",
      "                                                                                                  \n",
      " sequential_2 (Sequential)   (None, 50)                   7031666   ['input_3[0][0]']             \n",
      "                                                                                                  \n",
      " sequential (Sequential)     (None, 50)                   43386     ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " sequential_1 (Sequential)   (None, 50)                   3595995   ['input_2[0][0]']             \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " tf.expand_dims (TFOpLambda  (None, 1, 50)                0         ['sequential_2[0][0]']        \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.expand_dims_1 (TFOpLamb  (None, 1, 50)                0         ['sequential[0][0]']          \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.expand_dims_2 (TFOpLamb  (None, 1, 50)                0         ['sequential_1[0][0]']        \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention (Mult  (None, 1, 50)                40650     ['tf.expand_dims[0][0]',      \n",
      " iHeadAttention)                                                     'tf.expand_dims[0][0]']      \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (Mu  (None, 1, 50)                40650     ['tf.expand_dims_1[0][0]',    \n",
      " ltiHeadAttention)                                                   'tf.expand_dims_1[0][0]']    \n",
      "                                                                                                  \n",
      " multi_head_attention_2 (Mu  (None, 1, 50)                40650     ['tf.expand_dims_2[0][0]',    \n",
      " ltiHeadAttention)                                                   'tf.expand_dims_2[0][0]']    \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (  (None, 50)                   0         ['multi_head_attention[0][0]']\n",
      " SlicingOpLambda)                                                                                 \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1  (None, 50)                   0         ['multi_head_attention_1[0][0]\n",
      "  (SlicingOpLambda)                                                 ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2  (None, 50)                   0         ['multi_head_attention_2[0][0]\n",
      "  (SlicingOpLambda)                                                 ']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_3 (TFOpLamb  (None, 1, 50)                0         ['tf.__operators__.getitem[0][\n",
      " da)                                                                0]']                          \n",
      "                                                                                                  \n",
      " tf.expand_dims_4 (TFOpLamb  (None, 1, 50)                0         ['tf.__operators__.getitem_1[0\n",
      " da)                                                                ][0]']                        \n",
      "                                                                                                  \n",
      " tf.expand_dims_5 (TFOpLamb  (None, 1, 50)                0         ['tf.__operators__.getitem_2[0\n",
      " da)                                                                ][0]']                        \n",
      "                                                                                                  \n",
      " tf.expand_dims_6 (TFOpLamb  (None, 1, 50)                0         ['tf.__operators__.getitem[0][\n",
      " da)                                                                0]']                          \n",
      "                                                                                                  \n",
      " tf.expand_dims_7 (TFOpLamb  (None, 1, 50)                0         ['tf.__operators__.getitem_1[0\n",
      " da)                                                                ][0]']                        \n",
      "                                                                                                  \n",
      " tf.expand_dims_8 (TFOpLamb  (None, 1, 50)                0         ['tf.__operators__.getitem_2[0\n",
      " da)                                                                ][0]']                        \n",
      "                                                                                                  \n",
      " multi_head_attention_3 (Mu  (None, 1, 50)                40650     ['tf.expand_dims_3[0][0]',    \n",
      " ltiHeadAttention)                                                   'tf.expand_dims_4[0][0]']    \n",
      "                                                                                                  \n",
      " multi_head_attention_4 (Mu  (None, 1, 50)                40650     ['tf.expand_dims_4[0][0]',    \n",
      " ltiHeadAttention)                                                   'tf.expand_dims_3[0][0]']    \n",
      "                                                                                                  \n",
      " multi_head_attention_5 (Mu  (None, 1, 50)                40650     ['tf.expand_dims_5[0][0]',    \n",
      " ltiHeadAttention)                                                   'tf.expand_dims_6[0][0]']    \n",
      "                                                                                                  \n",
      " multi_head_attention_6 (Mu  (None, 1, 50)                40650     ['tf.expand_dims_6[0][0]',    \n",
      " ltiHeadAttention)                                                   'tf.expand_dims_5[0][0]']    \n",
      "                                                                                                  \n",
      " multi_head_attention_7 (Mu  (None, 1, 50)                40650     ['tf.expand_dims_7[0][0]',    \n",
      " ltiHeadAttention)                                                   'tf.expand_dims_8[0][0]']    \n",
      "                                                                                                  \n",
      " multi_head_attention_8 (Mu  (None, 1, 50)                40650     ['tf.expand_dims_8[0][0]',    \n",
      " ltiHeadAttention)                                                   'tf.expand_dims_7[0][0]']    \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_3  (None, 50)                   0         ['multi_head_attention_3[0][0]\n",
      "  (SlicingOpLambda)                                                 ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_4  (None, 50)                   0         ['multi_head_attention_4[0][0]\n",
      "  (SlicingOpLambda)                                                 ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_5  (None, 50)                   0         ['multi_head_attention_5[0][0]\n",
      "  (SlicingOpLambda)                                                 ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_6  (None, 50)                   0         ['multi_head_attention_6[0][0]\n",
      "  (SlicingOpLambda)                                                 ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_7  (None, 50)                   0         ['multi_head_attention_7[0][0]\n",
      "  (SlicingOpLambda)                                                 ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_8  (None, 50)                   0         ['multi_head_attention_8[0][0]\n",
      "  (SlicingOpLambda)                                                 ']                            \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 100)                  0         ['tf.__operators__.getitem_3[0\n",
      "                                                                    ][0]',                        \n",
      "                                                                     'tf.__operators__.getitem_4[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 100)                  0         ['tf.__operators__.getitem_5[0\n",
      " )                                                                  ][0]',                        \n",
      "                                                                     'tf.__operators__.getitem_6[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (None, 100)                  0         ['tf.__operators__.getitem_7[0\n",
      " )                                                                  ][0]',                        \n",
      "                                                                     'tf.__operators__.getitem_8[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate  (None, 450)                  0         ['concatenate[0][0]',         \n",
      " )                                                                   'concatenate_1[0][0]',       \n",
      "                                                                     'concatenate_2[0][0]',       \n",
      "                                                                     'sequential_2[0][0]',        \n",
      "                                                                     'sequential_1[0][0]',        \n",
      "                                                                     'sequential[0][0]']          \n",
      "                                                                                                  \n",
      " dense_7 (Dense)             (None, 3)                    1353      ['concatenate_3[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 43402205 (165.57 MB)\n",
      "Trainable params: 43400893 (165.56 MB)\n",
      "Non-trainable params: 1312 (5.12 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model, Model\n",
    "import numpy as np\n",
    "\n",
    "best_model = load_model('best_model.h5')\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 61ms/step\n",
      "2/2 [==============================] - 0s 21ms/step\n",
      "Training feature shape: (137, 450)\n",
      "Testing feature shape: (35, 450)\n"
     ]
    }
   ],
   "source": [
    "feature_extractor = Model(inputs=best_model.input, outputs=best_model.get_layer('concatenate_3').output) # Get merged layer\n",
    "\n",
    "train_features = feature_extractor.predict([train_clinical, train_snp, train_img])\n",
    "test_features = feature_extractor.predict([test_clinical, test_snp, test_img])\n",
    "\n",
    "print(f\"Training feature shape: {train_features.shape}\")\n",
    "print(f\"Testing feature shape: {test_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92        24\n",
      "           1       0.00      0.00      0.00         4\n",
      "           2       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           0.89        35\n",
      "   macro avg       0.62      0.67      0.64        35\n",
      "weighted avg       0.79      0.89      0.83        35\n",
      "\n",
      "Random Forest Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92        24\n",
      "           1       0.00      0.00      0.00         4\n",
      "           2       0.78      1.00      0.88         7\n",
      "\n",
      "    accuracy                           0.86        35\n",
      "   macro avg       0.55      0.65      0.60        35\n",
      "weighted avg       0.76      0.86      0.81        35\n",
      "\n",
      "SVM Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.79      0.88        24\n",
      "           1       0.43      0.75      0.55         4\n",
      "           2       0.78      1.00      0.88         7\n",
      "\n",
      "    accuracy                           0.83        35\n",
      "   macro avg       0.74      0.85      0.77        35\n",
      "weighted avg       0.89      0.83      0.84        35\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/flynnzhang/anaconda3/envs/Intro2DL/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/flynnzhang/anaconda3/envs/Intro2DL/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/flynnzhang/anaconda3/envs/Intro2DL/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/flynnzhang/anaconda3/envs/Intro2DL/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/flynnzhang/anaconda3/envs/Intro2DL/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/flynnzhang/anaconda3/envs/Intro2DL/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92        24\n",
      "           1       0.00      0.00      0.00         4\n",
      "           2       0.78      1.00      0.88         7\n",
      "\n",
      "    accuracy                           0.86        35\n",
      "   macro avg       0.55      0.65      0.60        35\n",
      "weighted avg       0.76      0.86      0.81        35\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/flynnzhang/anaconda3/envs/Intro2DL/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/flynnzhang/anaconda3/envs/Intro2DL/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/flynnzhang/anaconda3/envs/Intro2DL/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "y_train = train_label\n",
    "y_test = test_label\n",
    "\n",
    "# Logistic Regression\n",
    "log_reg = LogisticRegression()\n",
    "# log_reg = LogisticRegression(penalty='l2', C=0.1, solver='lbfgs', max_iter=200)\n",
    "log_reg.fit(train_features, y_train)\n",
    "y_pred_log_reg = log_reg.predict(test_features)\n",
    "print(\"Logistic Regression Report:\")\n",
    "print(classification_report(y_test, y_pred_log_reg))\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier()\n",
    "# rf = RandomForestClassifier(n_estimators=200, max_depth=10, min_samples_split=5, class_weight='balanced')\n",
    "rf.fit(train_features, y_train)\n",
    "y_pred_rf = rf.predict(test_features)\n",
    "print(\"Random Forest Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "\n",
    "# SVM\n",
    "svm = SVC()\n",
    "# svm = SVC(C=0.5, kernel='rbf', gamma='scale', class_weight='balanced', probability=True)\n",
    "svm.fit(train_features, y_train)\n",
    "y_pred_svm = svm.predict(test_features)\n",
    "print(\"SVM Report:\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "\n",
    "# XGBoost\n",
    "xgb = XGBClassifier()\n",
    "# xgb = XGBClassifier(n_estimators=200, learning_rate=0.1, max_depth=5, subsample=0.8, colsample_bytree=0.8)\n",
    "xgb.fit(train_features, y_train)\n",
    "y_pred_xgb = xgb.predict(test_features)\n",
    "print(\"XGBoost Report:\")\n",
    "print(classification_report(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/flynnzhang/anaconda3/envs/Intro2DL/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/flynnzhang/anaconda3/envs/Intro2DL/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/flynnzhang/anaconda3/envs/Intro2DL/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/flynnzhang/anaconda3/envs/Intro2DL/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/flynnzhang/anaconda3/envs/Intro2DL/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/flynnzhang/anaconda3/envs/Intro2DL/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/flynnzhang/anaconda3/envs/Intro2DL/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/flynnzhang/anaconda3/envs/Intro2DL/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/flynnzhang/anaconda3/envs/Intro2DL/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/flynnzhang/anaconda3/envs/Intro2DL/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/flynnzhang/anaconda3/envs/Intro2DL/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/flynnzhang/anaconda3/envs/Intro2DL/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/flynnzhang/anaconda3/envs/Intro2DL/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best param: {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Highest accuracy: 0.9706924315619968\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92        24\n",
      "           1       0.00      0.00      0.00         4\n",
      "           2       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           0.89        35\n",
      "   macro avg       0.62      0.67      0.64        35\n",
      "weighted avg       0.79      0.89      0.83        35\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/flynnzhang/anaconda3/envs/Intro2DL/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/flynnzhang/anaconda3/envs/Intro2DL/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/flynnzhang/anaconda3/envs/Intro2DL/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/flynnzhang/anaconda3/envs/Intro2DL/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid_lr = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.01, 0.1, 1, 10],\n",
    "    'solver': ['liblinear', 'saga']\n",
    "}\n",
    "\n",
    "grid_search_lr = GridSearchCV(\n",
    "    estimator=LogisticRegression(max_iter=1000),\n",
    "    param_grid=param_grid_lr,\n",
    "    scoring='accuracy',\n",
    "    cv=3\n",
    ")\n",
    "grid_search_lr.fit(train_features, y_train)\n",
    "\n",
    "print(\"Best param:\", grid_search_lr.best_params_)\n",
    "print(\"Highest accuracy:\", grid_search_lr.best_score_)\n",
    "\n",
    "best_lr_model = grid_search_lr.best_estimator_\n",
    "y_pred_lr = best_lr_model.predict(test_features)\n",
    "print(classification_report(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best param: {'class_weight': 'balanced', 'max_depth': None, 'min_samples_split': 10, 'n_estimators': 300}\n",
      "Highest accuracy: 0.926892109500805\n",
      "Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92        24\n",
      "           1       0.00      0.00      0.00         4\n",
      "           2       0.78      1.00      0.88         7\n",
      "\n",
      "    accuracy                           0.86        35\n",
      "   macro avg       0.55      0.65      0.60        35\n",
      "weighted avg       0.76      0.86      0.81        35\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/flynnzhang/anaconda3/envs/Intro2DL/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/flynnzhang/anaconda3/envs/Intro2DL/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/flynnzhang/anaconda3/envs/Intro2DL/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'class_weight': ['balanced', None]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=RandomForestClassifier(), param_grid=param_grid, cv=3, scoring='accuracy')\n",
    "grid_search.fit(train_features, y_train)\n",
    "\n",
    "print(\"Best param:\", grid_search.best_params_)\n",
    "print(\"Highest accuracy:\", grid_search.best_score_)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(test_features)\n",
    "print(\"Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best param: {'C': 1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Highest accuracy: 0.9561996779388084\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92        24\n",
      "           1       0.00      0.00      0.00         4\n",
      "           2       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           0.89        35\n",
      "   macro avg       0.62      0.67      0.64        35\n",
      "weighted avg       0.79      0.89      0.83        35\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/flynnzhang/anaconda3/envs/Intro2DL/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/flynnzhang/anaconda3/envs/Intro2DL/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/flynnzhang/anaconda3/envs/Intro2DL/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "grid_search_svm = GridSearchCV(\n",
    "    estimator=SVC(probability=True),\n",
    "    param_grid=param_grid_svm,\n",
    "    scoring='accuracy',\n",
    "    cv=3\n",
    ")\n",
    "grid_search_svm.fit(train_features, y_train)\n",
    "\n",
    "print(\"Best param:\", grid_search_svm.best_params_)\n",
    "print(\"Highest accuracy:\", grid_search_svm.best_score_)\n",
    "\n",
    "best_svm_model = grid_search_svm.best_estimator_\n",
    "y_pred_svm = best_svm_model.predict(test_features)\n",
    "print(classification_report(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best param: {'colsample_bytree': 1.0, 'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 100, 'subsample': 1.0}\n",
      "Highest accuracy: 0.9194847020933977\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92        24\n",
      "           1       0.00      0.00      0.00         4\n",
      "           2       0.78      1.00      0.88         7\n",
      "\n",
      "    accuracy                           0.86        35\n",
      "   macro avg       0.55      0.65      0.60        35\n",
      "weighted avg       0.76      0.86      0.81        35\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/flynnzhang/anaconda3/envs/Intro2DL/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/flynnzhang/anaconda3/envs/Intro2DL/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/flynnzhang/anaconda3/envs/Intro2DL/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "param_grid_xgb = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "grid_search_xgb = GridSearchCV(\n",
    "    estimator=XGBClassifier(eval_metric='mlogloss'),\n",
    "    param_grid=param_grid_xgb,\n",
    "    scoring='accuracy',\n",
    "    cv=3\n",
    ")\n",
    "grid_search_xgb.fit(train_features, y_train)\n",
    "\n",
    "print(\"Best param:\", grid_search_xgb.best_params_)\n",
    "print(\"Highest accuracy:\", grid_search_xgb.best_score_)\n",
    "\n",
    "best_xgb_model = grid_search_xgb.best_estimator_\n",
    "y_pred_xgb = best_xgb_model.predict(test_features)\n",
    "print(classification_report(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Intro2DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
