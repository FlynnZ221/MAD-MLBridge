{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import gc, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.utils import compute_class_weight\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense, Dropout,Flatten, BatchNormalization, Conv2D, MultiHeadAttention, concatenate\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, \n",
    "    BatchNormalization, \n",
    "    Activation, \n",
    "    MaxPooling2D, \n",
    "    GlobalAveragePooling2D, \n",
    "    Dense, \n",
    "    Input, \n",
    "    Add, \n",
    "    Dropout\n",
    ")\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMG - Resnet - acc: 0.83"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_img(t_img):\n",
    "    img = pd.read_pickle(t_img)\n",
    "    img_l = []\n",
    "    for i in range(len(img)):\n",
    "        img_l.append(img.values[i][0])\n",
    "    \n",
    "    return np.array(img_l)\n",
    "\n",
    "\n",
    "def reset_random_seeds(seed):\n",
    "    os.environ['PYTHONHASHSEED']=str(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "   \n",
    "               \n",
    "def create_model_snp():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(200,  activation = \"relu\")) \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(100, activation = \"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(50, activation = \"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    return model\n",
    "\n",
    "def create_model_clinical():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(128,  activation = \"relu\")) \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(128, activation = \"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(50, activation = \"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))    \n",
    "    return model\n",
    "\n",
    "def residual_block(x, filters, kernel_size=3, stride=1, conv_shortcut=True):\n",
    "    shortcut = x\n",
    "    \n",
    "    if conv_shortcut:\n",
    "        shortcut = Conv2D(filters, 1, strides=stride)(shortcut)\n",
    "        shortcut = BatchNormalization()(shortcut)\n",
    "    \n",
    "    x = Conv2D(filters, kernel_size, strides=stride, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2D(filters, kernel_size, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = Add()([shortcut, x])\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def create_model_img():\n",
    "    inputs = Input(shape=(train_img.shape[1], train_img.shape[2], train_img.shape[3]))\n",
    "    \n",
    "    # 初始卷积层\n",
    "    x = Conv2D(64, 7, strides=2, padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(3, strides=2, padding='same')(x)\n",
    "    \n",
    "    # ResNet blocks\n",
    "    x = residual_block(x, 64)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = residual_block(x, 64)\n",
    "    \n",
    "    x = residual_block(x, 128, stride=2)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = residual_block(x, 128)\n",
    "    \n",
    "    x = residual_block(x, 256, stride=2)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = residual_block(x, 256)\n",
    "    \n",
    "    # 全局平均池化\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # 全连接层\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(50, activation='relu')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "    return model\n",
    "\n",
    "\n",
    "def plot_classification_report(y_tru, y_prd, mode, learning_rate, batch_size,epochs, figsize=(7, 7), ax=None):\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    xticks = ['precision', 'recall', 'f1-score', 'support']\n",
    "    yticks = [\"Control\", \"Moderate\", \"Alzheimer's\" ] \n",
    "    yticks += ['avg']\n",
    "\n",
    "    rep = np.array(precision_recall_fscore_support(y_tru, y_prd)).T\n",
    "    avg = np.mean(rep, axis=0)\n",
    "    avg[-1] = np.sum(rep[:, -1])\n",
    "    rep = np.insert(rep, rep.shape[0], avg, axis=0)\n",
    "\n",
    "    sns.heatmap(rep,\n",
    "                annot=True, \n",
    "                cbar=False, \n",
    "                xticklabels=xticks, \n",
    "                yticklabels=yticks,\n",
    "                ax=ax, cmap = \"Blues\")\n",
    "    \n",
    "    plt.savefig('report_' + str(mode) + '_' + str(learning_rate) +'_' + str(batch_size)+'_' + str(epochs)+'.png')\n",
    "    \n",
    "\n",
    "\n",
    "def calc_confusion_matrix(result, test_label,mode, learning_rate, batch_size, epochs):\n",
    "    test_label = to_categorical(test_label,3)\n",
    "\n",
    "    true_label= np.argmax(test_label, axis =1)\n",
    "\n",
    "    predicted_label= np.argmax(result, axis =1)\n",
    "    \n",
    "    n_classes = 3\n",
    "    precision = dict()\n",
    "    recall = dict()\n",
    "    thres = dict()\n",
    "    for i in range(n_classes):\n",
    "        precision[i], recall[i], thres[i] = precision_recall_curve(test_label[:, i],\n",
    "                                                            result[:, i])\n",
    "\n",
    "\n",
    "    print (\"Classification Report :\") \n",
    "    print (classification_report(true_label, predicted_label))\n",
    "    cr = classification_report(true_label, predicted_label, output_dict=True)\n",
    "    return cr, precision, recall, thres\n",
    "\n",
    "\n",
    "\n",
    "def cross_modal_attention(x, y):\n",
    "    x = tf.expand_dims(x, axis=1)\n",
    "    y = tf.expand_dims(y, axis=1)\n",
    "    a1 = MultiHeadAttention(num_heads = 4,key_dim=50)(x, y)\n",
    "    a2 = MultiHeadAttention(num_heads = 4,key_dim=50)(y, x)\n",
    "    a1 = a1[:,0,:]\n",
    "    a2 = a2[:,0,:]\n",
    "    return concatenate([a1, a2])\n",
    "\n",
    "\n",
    "def self_attention(x):\n",
    "    x = tf.expand_dims(x, axis=1)\n",
    "    attention = MultiHeadAttention(num_heads = 4, key_dim=50)(x, x)\n",
    "    attention = attention[:,0,:]\n",
    "    return attention\n",
    "    \n",
    "\n",
    "def multi_modal_model(mode, train_clinical, train_snp, train_img):\n",
    "    \n",
    "    in_clinical = Input(shape=(train_clinical.shape[1]))\n",
    "    \n",
    "    in_snp = Input(shape=(train_snp.shape[1]))\n",
    "    \n",
    "    in_img = Input(shape=(train_img.shape[1], train_img.shape[2], train_img.shape[3]))\n",
    "    \n",
    "    dense_clinical = create_model_clinical()(in_clinical)\n",
    "    dense_snp = create_model_snp()(in_snp) \n",
    "    dense_img = create_model_img()(in_img) \n",
    "    \n",
    " \n",
    "        \n",
    "    ########### Attention Layer ############\n",
    "        \n",
    "    ## Cross Modal Bi-directional Attention ##\n",
    "\n",
    "    if mode == 'MM_BA':\n",
    "            \n",
    "        vt_att = cross_modal_attention(dense_img, dense_clinical)\n",
    "        av_att = cross_modal_attention(dense_snp, dense_img)\n",
    "        ta_att = cross_modal_attention(dense_clinical, dense_snp)\n",
    "                \n",
    "        merged = concatenate([vt_att, av_att, ta_att, dense_img, dense_snp, dense_clinical])\n",
    "                 \n",
    "   \n",
    "        \n",
    "        \n",
    "    ## Self Attention ##\n",
    "    elif mode == 'MM_SA':\n",
    "            \n",
    "        vv_att = self_attention(dense_img)\n",
    "        tt_att = self_attention(dense_clinical)\n",
    "        aa_att = self_attention(dense_snp)\n",
    "            \n",
    "        merged = concatenate([aa_att, vv_att, tt_att, dense_img, dense_snp, dense_clinical])\n",
    "        \n",
    "    ## Self Attention and Cross Modal Bi-directional Attention##\n",
    "    elif mode == 'MM_SA_BA':\n",
    "            \n",
    "        vv_att = self_attention(dense_img)\n",
    "        tt_att = self_attention(dense_clinical)\n",
    "        aa_att = self_attention(dense_snp)\n",
    "        \n",
    "        vt_att = cross_modal_attention(vv_att, tt_att)\n",
    "        av_att = cross_modal_attention(aa_att, vv_att)\n",
    "        ta_att = cross_modal_attention(tt_att, aa_att)\n",
    "            \n",
    "        merged = concatenate([vt_att, av_att, ta_att, dense_img, dense_snp, dense_clinical])\n",
    "            \n",
    "        \n",
    "    ## No Attention ##    \n",
    "    elif mode == 'None':\n",
    "            \n",
    "        merged = concatenate([dense_img, dense_snp, dense_clinical])\n",
    "                \n",
    "    else:\n",
    "        print (\"Mode must be one of 'MM_SA', 'MM_BA', 'MU_SA_BA' or 'None'.\")\n",
    "        return\n",
    "                \n",
    "        \n",
    "    ########### Output Layer ############\n",
    "        \n",
    "    output = Dense(3, activation='softmax')(merged)\n",
    "    model = Model([in_clinical, in_snp, in_img], output)        \n",
    "        \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def train(mode, batch_size, epochs, learning_rate, seed):\n",
    "    \n",
    "    # train_img = train_img.astype(\"float32\")\n",
    "\n",
    "    reset_random_seeds(seed)\n",
    "    class_weights = compute_class_weight(class_weight = 'balanced',classes = np.unique(train_label),y = train_label)\n",
    "    d_class_weights = dict(enumerate(class_weights))\n",
    "    \n",
    "    # compile model #\n",
    "    model = multi_modal_model(mode, train_clinical, train_snp, train_img)\n",
    "    model.compile(optimizer=Adam(learning_rate = learning_rate), loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
    "    \n",
    "\n",
    "    # summarize results\n",
    "    history = model.fit([train_clinical,\n",
    "                         train_snp,\n",
    "                         train_img],\n",
    "                        train_label,\n",
    "                        epochs=epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        class_weight=d_class_weights,\n",
    "                        validation_split=0.1,\n",
    "                        verbose=1)\n",
    "                        \n",
    "                \n",
    "\n",
    "    score = model.evaluate([test_clinical, test_snp, test_img], test_label)\n",
    "    \n",
    "    acc = score[1] \n",
    "    test_predictions = model.predict([test_clinical, test_snp, test_img])\n",
    "    cr, precision_d, recall_d, thres = calc_confusion_matrix(test_predictions, test_label, mode, learning_rate, batch_size, epochs)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    plt.clf()\n",
    "    plt.plot(history.history['sparse_categorical_accuracy'])\n",
    "    plt.plot(history.history['val_sparse_categorical_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()\n",
    "    plt.savefig('accuracy_' + str(mode) + '_' + str(learning_rate) +'_' + str(batch_size)+'.png')\n",
    "    plt.clf()\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()\n",
    "    plt.savefig('loss_' + str(mode) + '_' + str(learning_rate) +'_' + str(batch_size)+'.png')\n",
    "    plt.clf()\n",
    "    \"\"\"\n",
    "    \n",
    " \n",
    "    \n",
    "    # release gpu memory #\n",
    "    K.clear_session()\n",
    "    del model, history\n",
    "    gc.collect()\n",
    "        \n",
    "        \n",
    "    print ('Mode: ', mode)\n",
    "    print ('Batch size:  ', batch_size)\n",
    "    print ('Learning rate: ', learning_rate)\n",
    "    print ('Epochs:  ', epochs)\n",
    "    print ('Test Accuracy:', '{0:.4f}'.format(acc))\n",
    "    print ('-'*55)\n",
    "    \n",
    "    return acc, batch_size, learning_rate, epochs, seed\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clinical = pd.read_csv(\"../preprocess_overlap/X_train_clinical.csv\").values\n",
    "test_clinical= pd.read_csv(\"../preprocess_overlap/X_test_clinical.csv\").values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[True, False, False, ..., False, False, False],\n",
       "       [True, False, False, ..., True, False, False],\n",
       "       [True, False, False, ..., True, False, False],\n",
       "       ...,\n",
       "       [True, False, False, ..., False, False, False],\n",
       "       [True, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False]], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_clinical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_clinical = pd.read_csv(\"../preprocess_overlap/X_train_clinical.csv\").values\n",
    "test_clinical= pd.read_csv(\"../preprocess_overlap/X_test_clinical.csv\").values\n",
    "\n",
    "\n",
    "train_snp = pd.read_csv(\"../preprocess_overlap/X_train_snp.csv\").values\n",
    "test_snp = pd.read_csv(\"../preprocess_overlap/X_test_snp.csv\").values\n",
    "\n",
    "\n",
    "train_img= make_img(\"../preprocess_overlap/X_train_img.pkl\")\n",
    "test_img= make_img(\"../preprocess_overlap/X_test_img.pkl\")\n",
    "\n",
    "\n",
    "train_label= pd.read_csv(\"../preprocess_overlap/y_train.csv\").values.astype(\"int\").flatten()\n",
    "test_label= pd.read_csv(\"../preprocess_overlap/y_test.csv\").values.astype(\"int\").flatten()\n",
    "\n",
    "train_clinical = train_clinical.astype(\"float32\")\n",
    "test_clinical = test_clinical.astype(\"float32\")\n",
    "# train_snp = train_snp.astype(\"float32\")\n",
    "# train_snp = test_snp.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/18\n",
      "16/16 [==============================] - 8s 253ms/step - loss: 1.2757 - sparse_categorical_accuracy: 0.4065 - val_loss: 36.4873 - val_sparse_categorical_accuracy: 0.6429\n",
      "Epoch 2/18\n",
      "16/16 [==============================] - 3s 184ms/step - loss: 1.0470 - sparse_categorical_accuracy: 0.4228 - val_loss: 30.3702 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 3/18\n",
      "16/16 [==============================] - 3s 184ms/step - loss: 0.7634 - sparse_categorical_accuracy: 0.6504 - val_loss: 7.5396 - val_sparse_categorical_accuracy: 0.5714\n",
      "Epoch 4/18\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.7212 - sparse_categorical_accuracy: 0.6911 - val_loss: 2.3999 - val_sparse_categorical_accuracy: 0.7857\n",
      "Epoch 5/18\n",
      "16/16 [==============================] - 3s 178ms/step - loss: 0.5931 - sparse_categorical_accuracy: 0.7886 - val_loss: 2.0556 - val_sparse_categorical_accuracy: 0.7857\n",
      "Epoch 6/18\n",
      "16/16 [==============================] - 3s 197ms/step - loss: 0.4376 - sparse_categorical_accuracy: 0.7805 - val_loss: 0.8099 - val_sparse_categorical_accuracy: 0.8571\n",
      "Epoch 7/18\n",
      "16/16 [==============================] - 3s 179ms/step - loss: 0.3780 - sparse_categorical_accuracy: 0.8374 - val_loss: 0.3415 - val_sparse_categorical_accuracy: 0.7857\n",
      "Epoch 8/18\n",
      "16/16 [==============================] - 3s 177ms/step - loss: 0.4656 - sparse_categorical_accuracy: 0.7967 - val_loss: 0.3112 - val_sparse_categorical_accuracy: 0.7857\n",
      "Epoch 9/18\n",
      "16/16 [==============================] - 3s 185ms/step - loss: 0.3993 - sparse_categorical_accuracy: 0.7805 - val_loss: 1.5274 - val_sparse_categorical_accuracy: 0.3571\n",
      "Epoch 10/18\n",
      "16/16 [==============================] - 3s 176ms/step - loss: 0.3920 - sparse_categorical_accuracy: 0.8455 - val_loss: 0.8159 - val_sparse_categorical_accuracy: 0.5000\n",
      "Epoch 11/18\n",
      "16/16 [==============================] - 3s 181ms/step - loss: 0.3511 - sparse_categorical_accuracy: 0.8699 - val_loss: 0.9887 - val_sparse_categorical_accuracy: 0.7857\n",
      "Epoch 12/18\n",
      "16/16 [==============================] - 3s 215ms/step - loss: 0.5109 - sparse_categorical_accuracy: 0.8537 - val_loss: 1.1514 - val_sparse_categorical_accuracy: 0.7857\n",
      "Epoch 13/18\n",
      "16/16 [==============================] - 3s 184ms/step - loss: 0.4218 - sparse_categorical_accuracy: 0.8211 - val_loss: 0.8752 - val_sparse_categorical_accuracy: 0.7857\n",
      "Epoch 14/18\n",
      "16/16 [==============================] - 3s 202ms/step - loss: 0.4674 - sparse_categorical_accuracy: 0.7480 - val_loss: 1.8294 - val_sparse_categorical_accuracy: 0.7143\n",
      "Epoch 15/18\n",
      "16/16 [==============================] - 5s 343ms/step - loss: 0.3745 - sparse_categorical_accuracy: 0.7480 - val_loss: 0.2951 - val_sparse_categorical_accuracy: 0.8571\n",
      "Epoch 16/18\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 0.2434 - sparse_categorical_accuracy: 0.8862 - val_loss: 0.2129 - val_sparse_categorical_accuracy: 0.8571\n",
      "Epoch 17/18\n",
      "16/16 [==============================] - 3s 183ms/step - loss: 0.2130 - sparse_categorical_accuracy: 0.9106 - val_loss: 0.2583 - val_sparse_categorical_accuracy: 0.8571\n",
      "Epoch 18/18\n",
      "16/16 [==============================] - 3s 185ms/step - loss: 0.1717 - sparse_categorical_accuracy: 0.8943 - val_loss: 0.1816 - val_sparse_categorical_accuracy: 0.9286\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.5529 - sparse_categorical_accuracy: 0.8571\n",
      "2/2 [==============================] - 1s 20ms/step\n",
      "Classification Report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92        24\n",
      "           1       0.00      0.00      0.00         4\n",
      "           2       0.78      1.00      0.88         7\n",
      "\n",
      "    accuracy                           0.86        35\n",
      "   macro avg       0.55      0.65      0.60        35\n",
      "weighted avg       0.76      0.86      0.81        35\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanicewan/anaconda3/envs/idls24/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yanicewan/anaconda3/envs/idls24/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yanicewan/anaconda3/envs/idls24/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yanicewan/anaconda3/envs/idls24/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yanicewan/anaconda3/envs/idls24/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yanicewan/anaconda3/envs/idls24/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode:  MM_SA_BA\n",
      "Batch size:   8\n",
      "Learning rate:  0.001\n",
      "Epochs:   18\n",
      "Test Accuracy: 0.8571\n",
      "-------------------------------------------------------\n",
      "{0.8571428656578064: ('MM_SA_BA', 0.8571428656578064, 8, 0.001, 18, 45)}\n",
      "-------------------------------------------------------\n",
      "Highest accuracy of: 0.8571428656578064 with parameters: ('MM_SA_BA', 0.8571428656578064, 8, 0.001, 18, 45)\n"
     ]
    }
   ],
   "source": [
    "m_a = {}\n",
    "seeds = random.sample(range(1, 200), 1)\n",
    "for s in seeds:\n",
    "    acc, bs_, lr_, e_ , seed= train('MM_SA_BA', 8, 18, 0.001, 45)\n",
    "    m_a[acc] = ('MM_SA_BA', acc, bs_, lr_, e_, seed)\n",
    "print(m_a)\n",
    "print ('-'*55)\n",
    "max_acc = max(m_a, key=float)\n",
    "print(\"Highest accuracy of: \" + str(max_acc) + \" with parameters: \" + str(m_a[max_acc]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, ..., 0, 1, 1],\n",
       "       [0, 2, 0, ..., 0, 2, 2],\n",
       "       [0, 2, 0, ..., 0, 2, 2],\n",
       "       ...,\n",
       "       [0, 2, 0, ..., 0, 2, 2],\n",
       "       [0, 2, 0, ..., 0, 2, 2],\n",
       "       [0, 2, 0, ..., 0, 2, 2]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_snp = pd.read_csv(\"../preprocess_overlap/X_train_snp.csv\").values\n",
    "test_snp = pd.read_csv(\"../preprocess_overlap/X_test_snp.csv\").values\n",
    "train_snp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_clinical shape: (71, 149)\n",
      "train_snp shape: (71, 179666)\n",
      "train_img shape: (71, 72, 72, 3)\n",
      "train_label shape: (71,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"train_clinical shape:\", train_clinical.shape)\n",
    "print(\"train_snp shape:\", train_snp.shape)\n",
    "print(\"train_img shape:\", train_img.shape)\n",
    "print(\"train_label shape:\", train_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集类别分布: [41 30]\n",
      "验证集类别分布: [5 3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(\"训练集类别分布:\", np.bincount(train_label))\n",
    "print(\"验证集类别分布:\", np.bincount(test_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GoogleNet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "def make_img(t_img):\n",
    "    img = pd.read_pickle(t_img)\n",
    "    img_l = []\n",
    "    for i in range(len(img)):\n",
    "        img_l.append(img.values[i][0])\n",
    "    \n",
    "    return np.array(img_l)\n",
    "\n",
    "\n",
    "def reset_random_seeds(seed):\n",
    "    os.environ['PYTHONHASHSEED']=str(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "   \n",
    "               \n",
    "def create_model_snp():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(200,  activation = \"relu\")) \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, activation = \"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Dense(50, activation = \"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    return model\n",
    "\n",
    "def create_model_clinical():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(200,  activation = \"relu\")) \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, activation = \"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(50, activation = \"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))    \n",
    "    return model\n",
    "\n",
    "def inception_module(x, filters_1x1, filters_3x3_reduce, filters_3x3, filters_5x5_reduce, filters_5x5, filters_pool):\n",
    "    # 1x1 convolution branch\n",
    "    conv1x1 = Conv2D(filters_1x1, (1, 1), padding='same')(x)\n",
    "    conv1x1 = BatchNormalization()(conv1x1)\n",
    "    conv1x1 = Activation('relu')(conv1x1)\n",
    "    \n",
    "    # 3x3 convolution branch\n",
    "    conv3x3 = Conv2D(filters_3x3_reduce, (1, 1), padding='same')(x)\n",
    "    conv3x3 = BatchNormalization()(conv3x3)\n",
    "    conv3x3 = Activation('relu')(conv3x3)\n",
    "    conv3x3 = Conv2D(filters_3x3, (3, 3), padding='same')(conv3x3)\n",
    "    conv3x3 = BatchNormalization()(conv3x3)\n",
    "    conv3x3 = Activation('relu')(conv3x3)\n",
    "    \n",
    "    # 5x5 convolution branch\n",
    "    conv5x5 = Conv2D(filters_5x5_reduce, (1, 1), padding='same')(x)\n",
    "    conv5x5 = BatchNormalization()(conv5x5)\n",
    "    conv5x5 = Activation('relu')(conv5x5)\n",
    "    conv5x5 = Conv2D(filters_5x5, (5, 5), padding='same')(conv5x5)\n",
    "    conv5x5 = BatchNormalization()(conv5x5)\n",
    "    conv5x5 = Activation('relu')(conv5x5)\n",
    "    \n",
    "    # Max pooling branch\n",
    "    pool = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
    "    pool = Conv2D(filters_pool, (1, 1), padding='same')(pool)\n",
    "    pool = BatchNormalization()(pool)\n",
    "    pool = Activation('relu')(pool)\n",
    "    \n",
    "    # Concatenate all branches\n",
    "    output = concatenate([conv1x1, conv3x3, conv5x5, pool], axis=-1)\n",
    "    return output\n",
    "\n",
    "def create_model_img():\n",
    "    inputs = Input(shape=(train_img.shape[1], train_img.shape[2], train_img.shape[3]))\n",
    "    \n",
    "    # Initial convolution\n",
    "    x = Conv2D(64, 7, strides=2, padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(3, strides=2, padding='same')(x)\n",
    "    \n",
    "    # First Inception modules\n",
    "    x = inception_module(x, 64, 96, 128, 16, 32, 32)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = inception_module(x, 128, 128, 192, 32, 96, 64)\n",
    "    x = MaxPooling2D(3, strides=2, padding='same')(x)\n",
    "    \n",
    "    # Middle Inception modules\n",
    "    x = inception_module(x, 192, 96, 208, 16, 48, 64)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = inception_module(x, 160, 112, 224, 24, 64, 64)\n",
    "    x = inception_module(x, 128, 128, 256, 24, 64, 64)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = inception_module(x, 112, 144, 288, 32, 64, 64)\n",
    "    \n",
    "    # Global average pooling\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # Dense layers\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(50, activation='relu')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "    return model\n",
    "\n",
    "def plot_classification_report(y_tru, y_prd, mode, learning_rate, batch_size,epochs, figsize=(7, 7), ax=None):\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    xticks = ['precision', 'recall', 'f1-score', 'support']\n",
    "    yticks = [\"Control\", \"Moderate\", \"Alzheimer's\" ] \n",
    "    yticks += ['avg']\n",
    "\n",
    "    rep = np.array(precision_recall_fscore_support(y_tru, y_prd)).T\n",
    "    avg = np.mean(rep, axis=0)\n",
    "    avg[-1] = np.sum(rep[:, -1])\n",
    "    rep = np.insert(rep, rep.shape[0], avg, axis=0)\n",
    "\n",
    "    sns.heatmap(rep,\n",
    "                annot=True, \n",
    "                cbar=False, \n",
    "                xticklabels=xticks, \n",
    "                yticklabels=yticks,\n",
    "                ax=ax, cmap = \"Blues\")\n",
    "    \n",
    "    plt.savefig('report_' + str(mode) + '_' + str(learning_rate) +'_' + str(batch_size)+'_' + str(epochs)+'.png')\n",
    "    \n",
    "\n",
    "\n",
    "def calc_confusion_matrix(result, test_label,mode, learning_rate, batch_size, epochs):\n",
    "    test_label = to_categorical(test_label,3)\n",
    "\n",
    "    true_label= np.argmax(test_label, axis =1)\n",
    "\n",
    "    predicted_label= np.argmax(result, axis =1)\n",
    "    \n",
    "    n_classes = 3\n",
    "    precision = dict()\n",
    "    recall = dict()\n",
    "    thres = dict()\n",
    "    for i in range(n_classes):\n",
    "        precision[i], recall[i], thres[i] = precision_recall_curve(test_label[:, i],\n",
    "                                                            result[:, i])\n",
    "\n",
    "\n",
    "    print (\"Classification Report :\") \n",
    "    print (classification_report(true_label, predicted_label))\n",
    "    cr = classification_report(true_label, predicted_label, output_dict=True)\n",
    "    return cr, precision, recall, thres\n",
    "\n",
    "\n",
    "\n",
    "def cross_modal_attention(x, y):\n",
    "    x = tf.expand_dims(x, axis=1)\n",
    "    y = tf.expand_dims(y, axis=1)\n",
    "    a1 = MultiHeadAttention(num_heads = 4,key_dim=50)(x, y)\n",
    "    a2 = MultiHeadAttention(num_heads = 4,key_dim=50)(y, x)\n",
    "    a1 = a1[:,0,:]\n",
    "    a2 = a2[:,0,:]\n",
    "    return concatenate([a1, a2])\n",
    "\n",
    "\n",
    "def self_attention(x):\n",
    "    x = tf.expand_dims(x, axis=1)\n",
    "    attention = MultiHeadAttention(num_heads = 4, key_dim=50)(x, x)\n",
    "    attention = attention[:,0,:]\n",
    "    return attention\n",
    "    \n",
    "\n",
    "def multi_modal_model(mode, train_clinical, train_snp, train_img):\n",
    "    \n",
    "    in_clinical = Input(shape=(train_clinical.shape[1]))\n",
    "    \n",
    "    in_snp = Input(shape=(train_snp.shape[1]))\n",
    "    \n",
    "    in_img = Input(shape=(train_img.shape[1], train_img.shape[2], train_img.shape[3]))\n",
    "    \n",
    "    dense_clinical = create_model_clinical()(in_clinical)\n",
    "    dense_snp = create_model_snp()(in_snp) \n",
    "    dense_img = create_model_img()(in_img) \n",
    "    \n",
    " \n",
    "        \n",
    "    ########### Attention Layer ############\n",
    "        \n",
    "    ## Cross Modal Bi-directional Attention ##\n",
    "\n",
    "    if mode == 'MM_BA':\n",
    "            \n",
    "        vt_att = cross_modal_attention(dense_img, dense_clinical)\n",
    "        av_att = cross_modal_attention(dense_snp, dense_img)\n",
    "        ta_att = cross_modal_attention(dense_clinical, dense_snp)\n",
    "                \n",
    "        merged = concatenate([vt_att, av_att, ta_att, dense_img, dense_snp, dense_clinical])\n",
    "                 \n",
    "   \n",
    "        \n",
    "        \n",
    "    ## Self Attention ##\n",
    "    elif mode == 'MM_SA':\n",
    "            \n",
    "        vv_att = self_attention(dense_img)\n",
    "        tt_att = self_attention(dense_clinical)\n",
    "        aa_att = self_attention(dense_snp)\n",
    "            \n",
    "        merged = concatenate([aa_att, vv_att, tt_att, dense_img, dense_snp, dense_clinical])\n",
    "        \n",
    "    ## Self Attention and Cross Modal Bi-directional Attention##\n",
    "    elif mode == 'MM_SA_BA':\n",
    "            \n",
    "        vv_att = self_attention(dense_img)\n",
    "        tt_att = self_attention(dense_clinical)\n",
    "        aa_att = self_attention(dense_snp)\n",
    "        \n",
    "        vt_att = cross_modal_attention(vv_att, tt_att)\n",
    "        av_att = cross_modal_attention(aa_att, vv_att)\n",
    "        ta_att = cross_modal_attention(tt_att, aa_att)\n",
    "            \n",
    "        merged = concatenate([vt_att, av_att, ta_att, dense_img, dense_snp, dense_clinical])\n",
    "            \n",
    "        \n",
    "    ## No Attention ##    \n",
    "    elif mode == 'None':\n",
    "            \n",
    "        merged = concatenate([dense_img, dense_snp, dense_clinical])\n",
    "                \n",
    "    else:\n",
    "        print (\"Mode must be one of 'MM_SA', 'MM_BA', 'MU_SA_BA' or 'None'.\")\n",
    "        return\n",
    "                \n",
    "        \n",
    "    ########### Output Layer ############\n",
    "        \n",
    "    output = Dense(3, activation='softmax')(merged)\n",
    "    model = Model([in_clinical, in_snp, in_img], output)        \n",
    "        \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def train(mode, batch_size, epochs, learning_rate, seed):\n",
    "    \n",
    "    # train_img = train_img.astype(\"float32\")\n",
    "\n",
    "    reset_random_seeds(seed)\n",
    "    class_weights = compute_class_weight(class_weight = 'balanced',classes = np.unique(train_label),y = train_label)\n",
    "    d_class_weights = dict(enumerate(class_weights))\n",
    "    \n",
    "    # compile model #\n",
    "    model = multi_modal_model(mode, train_clinical, train_snp, train_img)\n",
    "    model.compile(optimizer=Adam(learning_rate = learning_rate), loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
    "    callbacks = [\n",
    "        EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=10,\n",
    "            restore_best_weights=True,\n",
    "            mode='min'\n",
    "        ),\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=10,\n",
    "            min_lr=1e-6,\n",
    "            mode='min'\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # summarize results\n",
    "    history = model.fit([train_clinical,\n",
    "                         train_snp,\n",
    "                         train_img],\n",
    "                        train_label,\n",
    "                        epochs=epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        class_weight=d_class_weights,\n",
    "                        validation_split=0.1,\n",
    "                        verbose=1,\n",
    "                        callbacks = callbacks)\n",
    "                        \n",
    "                \n",
    "\n",
    "    score = model.evaluate([test_clinical, test_snp, test_img], test_label)\n",
    "    \n",
    "    acc = score[1] \n",
    "    test_predictions = model.predict([test_clinical, test_snp, test_img])\n",
    "    cr, precision_d, recall_d, thres = calc_confusion_matrix(test_predictions, test_label, mode, learning_rate, batch_size, epochs)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    plt.clf()\n",
    "    plt.plot(history.history['sparse_categorical_accuracy'])\n",
    "    plt.plot(history.history['val_sparse_categorical_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()\n",
    "    plt.savefig('accuracy_' + str(mode) + '_' + str(learning_rate) +'_' + str(batch_size)+'.png')\n",
    "    plt.clf()\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()\n",
    "    plt.savefig('loss_' + str(mode) + '_' + str(learning_rate) +'_' + str(batch_size)+'.png')\n",
    "    plt.clf()\n",
    "    \"\"\"\n",
    "    \n",
    " \n",
    "    \n",
    "    # release gpu memory #\n",
    "    K.clear_session()\n",
    "    del model, history\n",
    "    gc.collect()\n",
    "        \n",
    "        \n",
    "    print ('Mode: ', mode)\n",
    "    print ('Batch size:  ', batch_size)\n",
    "    print ('Learning rate: ', learning_rate)\n",
    "    print ('Epochs:  ', epochs)\n",
    "    print ('Test Accuracy:', '{0:.4f}'.format(acc))\n",
    "    print ('-'*55)\n",
    "    \n",
    "    return acc, batch_size, learning_rate, epochs, seed\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "16/16 [==============================] - 11s 376ms/step - loss: 1.3063 - sparse_categorical_accuracy: 0.4309 - val_loss: 2.0945 - val_sparse_categorical_accuracy: 0.4286 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 5s 300ms/step - loss: 0.9908 - sparse_categorical_accuracy: 0.5610 - val_loss: 16.5541 - val_sparse_categorical_accuracy: 0.3571 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 5s 293ms/step - loss: 0.8650 - sparse_categorical_accuracy: 0.6585 - val_loss: 2.1689 - val_sparse_categorical_accuracy: 0.7143 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 5s 336ms/step - loss: 0.5342 - sparse_categorical_accuracy: 0.7236 - val_loss: 0.6543 - val_sparse_categorical_accuracy: 0.7143 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 7s 421ms/step - loss: 0.4489 - sparse_categorical_accuracy: 0.8211 - val_loss: 0.5515 - val_sparse_categorical_accuracy: 0.7857 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 5s 330ms/step - loss: 0.4286 - sparse_categorical_accuracy: 0.8618 - val_loss: 0.4355 - val_sparse_categorical_accuracy: 0.8571 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 5s 337ms/step - loss: 0.5398 - sparse_categorical_accuracy: 0.7236 - val_loss: 0.6971 - val_sparse_categorical_accuracy: 0.7143 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 5s 331ms/step - loss: 0.3830 - sparse_categorical_accuracy: 0.7724 - val_loss: 0.3929 - val_sparse_categorical_accuracy: 0.8571 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 5s 349ms/step - loss: 0.2748 - sparse_categorical_accuracy: 0.8374 - val_loss: 0.4513 - val_sparse_categorical_accuracy: 0.7857 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "16/16 [==============================] - 6s 396ms/step - loss: 0.4180 - sparse_categorical_accuracy: 0.8211 - val_loss: 0.3517 - val_sparse_categorical_accuracy: 0.7857 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "16/16 [==============================] - 5s 300ms/step - loss: 0.4489 - sparse_categorical_accuracy: 0.7154 - val_loss: 0.6904 - val_sparse_categorical_accuracy: 0.7857 - lr: 0.0010\n",
      "Epoch 12/30\n",
      "16/16 [==============================] - 6s 362ms/step - loss: 0.4106 - sparse_categorical_accuracy: 0.8862 - val_loss: 0.5895 - val_sparse_categorical_accuracy: 0.7857 - lr: 0.0010\n",
      "Epoch 13/30\n",
      "16/16 [==============================] - 5s 292ms/step - loss: 0.2668 - sparse_categorical_accuracy: 0.8130 - val_loss: 0.3848 - val_sparse_categorical_accuracy: 0.7857 - lr: 0.0010\n",
      "Epoch 14/30\n",
      "16/16 [==============================] - 5s 321ms/step - loss: 0.1707 - sparse_categorical_accuracy: 0.9106 - val_loss: 0.2633 - val_sparse_categorical_accuracy: 0.8571 - lr: 0.0010\n",
      "Epoch 15/30\n",
      "16/16 [==============================] - 5s 291ms/step - loss: 0.1728 - sparse_categorical_accuracy: 0.9268 - val_loss: 0.2350 - val_sparse_categorical_accuracy: 0.8571 - lr: 0.0010\n",
      "Epoch 16/30\n",
      "16/16 [==============================] - 5s 337ms/step - loss: 0.2307 - sparse_categorical_accuracy: 0.8618 - val_loss: 0.6526 - val_sparse_categorical_accuracy: 0.8571 - lr: 0.0010\n",
      "Epoch 17/30\n",
      "16/16 [==============================] - 5s 308ms/step - loss: 0.3121 - sparse_categorical_accuracy: 0.8293 - val_loss: 0.7925 - val_sparse_categorical_accuracy: 0.8571 - lr: 0.0010\n",
      "Epoch 18/30\n",
      "16/16 [==============================] - 5s 289ms/step - loss: 0.2010 - sparse_categorical_accuracy: 0.8943 - val_loss: 0.7221 - val_sparse_categorical_accuracy: 0.8571 - lr: 0.0010\n",
      "Epoch 19/30\n",
      "16/16 [==============================] - 5s 293ms/step - loss: 0.3517 - sparse_categorical_accuracy: 0.9106 - val_loss: 0.8574 - val_sparse_categorical_accuracy: 0.8571 - lr: 0.0010\n",
      "Epoch 20/30\n",
      "16/16 [==============================] - 7s 425ms/step - loss: 0.4650 - sparse_categorical_accuracy: 0.8618 - val_loss: 0.7008 - val_sparse_categorical_accuracy: 0.8571 - lr: 0.0010\n",
      "Epoch 21/30\n",
      "16/16 [==============================] - 7s 419ms/step - loss: 0.1956 - sparse_categorical_accuracy: 0.8699 - val_loss: 0.6005 - val_sparse_categorical_accuracy: 0.8571 - lr: 0.0010\n",
      "Epoch 22/30\n",
      "16/16 [==============================] - 5s 305ms/step - loss: 0.2107 - sparse_categorical_accuracy: 0.9187 - val_loss: 0.5952 - val_sparse_categorical_accuracy: 0.8571 - lr: 0.0010\n",
      "Epoch 23/30\n",
      "16/16 [==============================] - 5s 295ms/step - loss: 0.1030 - sparse_categorical_accuracy: 0.9756 - val_loss: 0.6072 - val_sparse_categorical_accuracy: 0.8571 - lr: 0.0010\n",
      "Epoch 24/30\n",
      "16/16 [==============================] - 5s 329ms/step - loss: 0.1398 - sparse_categorical_accuracy: 0.9187 - val_loss: 0.6790 - val_sparse_categorical_accuracy: 0.8571 - lr: 0.0010\n",
      "Epoch 25/30\n",
      "16/16 [==============================] - 7s 421ms/step - loss: 0.1624 - sparse_categorical_accuracy: 0.8862 - val_loss: 0.7261 - val_sparse_categorical_accuracy: 0.7857 - lr: 0.0010\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.3873 - sparse_categorical_accuracy: 0.8571\n",
      "2/2 [==============================] - 1s 32ms/step\n",
      "Classification Report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.88      0.91        24\n",
      "           1       0.50      0.50      0.50         4\n",
      "           2       0.78      1.00      0.88         7\n",
      "\n",
      "    accuracy                           0.86        35\n",
      "   macro avg       0.74      0.79      0.76        35\n",
      "weighted avg       0.87      0.86      0.86        35\n",
      "\n",
      "Mode:  MM_SA_BA\n",
      "Batch size:   8\n",
      "Learning rate:  0.001\n",
      "Epochs:   30\n",
      "Test Accuracy: 0.8571\n",
      "-------------------------------------------------------\n",
      "{0.8571428656578064: ('MM_SA_BA', 0.8571428656578064, 8, 0.001, 30, 3)}\n",
      "-------------------------------------------------------\n",
      "Highest accuracy of: 0.8571428656578064 with parameters: ('MM_SA_BA', 0.8571428656578064, 8, 0.001, 30, 3)\n"
     ]
    }
   ],
   "source": [
    "m_a = {}\n",
    "seeds = random.sample(range(1, 200), 1)\n",
    "for s in seeds:\n",
    "    acc, bs_, lr_, e_ , seed= train('MM_SA_BA', 8, 30, 0.001, s)\n",
    "    m_a[acc] = ('MM_SA_BA', acc, bs_, lr_, e_, seed)\n",
    "print(m_a)\n",
    "print ('-'*55)\n",
    "max_acc = max(m_a, key=float)\n",
    "print(\"Highest accuracy of: \" + str(max_acc) + \" with parameters: \" + str(m_a[max_acc]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SNP - CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Input, concatenate\n",
    "from tensorflow.keras.layers import Conv2D, Conv1D,Conv2D, Flatten, MultiHeadAttention\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support, precision_recall_curve\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "import gc\n",
    "import os\n",
    "import random\n",
    "\n",
    "def reset_random_seeds(seed):\n",
    "    os.environ['PYTHONHASHSEED']=str(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "def create_model_snp():\n",
    "    model = Sequential([\n",
    "        Conv1D(64, kernel_size=5, activation=\"relu\", input_shape=(input_shape, 1)),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Dropout(config[\"dropout\"]),\n",
    "\n",
    "        Conv1D(128, kernel_size=3, activation=\"relu\"),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Dropout(config[\"dropout\"]),\n",
    "\n",
    "        Flatten(),\n",
    "        Dense(128, activation=\"relu\"),\n",
    "        BatchNormalization(),\n",
    "        Dropout(config[\"dropout\"]),\n",
    "\n",
    "        Dense(50, activation=\"softmax\")\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def create_model_clinical():\n",
    "    model = Sequential([\n",
    "        Dense(128, activation=\"relu\"),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "        Dense(128, activation=\"relu\"),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "        Dense(50, activation=\"relu\"),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def create_model_img():\n",
    "    model = Sequential([\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.4),\n",
    "        Conv2D(32, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.4),\n",
    "        Flatten(),\n",
    "        Dense(50, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def simplified_attention(x, y):\n",
    "    \"\"\"简化的注意力机制\"\"\"\n",
    "    x = tf.expand_dims(x, axis=1)\n",
    "    y = tf.expand_dims(y, axis=1)\n",
    "    attention = MultiHeadAttention(num_heads=2, key_dim=25)(x, y)\n",
    "    return attention[:,0,:]\n",
    "\n",
    "def multi_modal_model(mode, train_clinical, train_snp, train_img):\n",
    "    # 输入层\n",
    "    in_clinical = Input(shape=(train_clinical.shape[1]))\n",
    "    in_snp = Input(shape=(train_snp.shape[1]))\n",
    "    in_img = Input(shape=(train_img.shape[1], train_img.shape[2], train_img.shape[3]))\n",
    "    \n",
    "    # 特征提取\n",
    "    dense_clinical = create_model_clinical()(in_clinical)\n",
    "    dense_snp = create_model_snp()(in_snp)\n",
    "    dense_img = create_model_img()(in_img)\n",
    "    \n",
    "    # 简化的注意力机制\n",
    "    if mode == 'MM_SA_BA':\n",
    "        # 只保留最重要的跨模态注意力\n",
    "        img_clinical_att = simplified_attention(dense_img, dense_clinical)\n",
    "        snp_clinical_att = simplified_attention(dense_snp, dense_clinical)\n",
    "        merged = concatenate([img_clinical_att, snp_clinical_att, dense_img, dense_snp, dense_clinical])\n",
    "    else:\n",
    "        merged = concatenate([dense_img, dense_snp, dense_clinical])\n",
    "    \n",
    "    # 添加额外的整合层\n",
    "    merged = Dense(100, activation='relu')(merged)\n",
    "    merged = BatchNormalization()(merged)\n",
    "    merged = Dropout(0.5)(merged)\n",
    "    merged = Dense(50, activation='relu')(merged)\n",
    "    merged = BatchNormalization()(merged)\n",
    "    merged = Dropout(0.3)(merged)\n",
    "    \n",
    "    # 输出层\n",
    "    output = Dense(3, activation='softmax')(merged)\n",
    "    model = Model([in_clinical, in_snp, in_img], output)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train(mode, batch_size, epochs, learning_rate, seed):\n",
    "    reset_random_seeds(seed)\n",
    "    \n",
    "    # 计算类别权重\n",
    "    class_weights = compute_class_weight(\n",
    "        class_weight='balanced',\n",
    "        classes=np.unique(train_label),\n",
    "        y=train_label\n",
    "    )\n",
    "    d_class_weights = dict(enumerate(class_weights))\n",
    "    \n",
    "    # 创建和编译模型\n",
    "    model = multi_modal_model(mode, train_clinical, train_snp, train_img)\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['sparse_categorical_accuracy']\n",
    "    )\n",
    "    \n",
    "    # 回调函数\n",
    "    callbacks = [\n",
    "        EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=10,\n",
    "            restore_best_weights=True,\n",
    "            mode='min'\n",
    "        ),\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=5,\n",
    "            min_lr=1e-6,\n",
    "            mode='min'\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # 训练模型\n",
    "    history = model.fit(\n",
    "        [train_clinical, train_snp, train_img],\n",
    "        train_label,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        class_weight=d_class_weights,\n",
    "        validation_split=0.2,  # 增加验证集比例\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # 评估模型\n",
    "    score = model.evaluate([test_clinical, test_snp, test_img], test_label)\n",
    "    acc = score[1]\n",
    "    test_predictions = model.predict([test_clinical, test_snp, test_img])\n",
    "    \n",
    "    # 输出分类报告\n",
    "    pred_labels = np.argmax(test_predictions, axis=1)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(test_label, pred_labels))\n",
    "    \n",
    "    # 清理内存\n",
    "    K.clear_session()\n",
    "    del model, history\n",
    "    gc.collect()\n",
    "    \n",
    "    print(f'Mode: {mode}')\n",
    "    print(f'Batch size: {batch_size}')\n",
    "    print(f'Learning rate: {learning_rate}')\n",
    "    print(f'Epochs: {epochs}')\n",
    "    print(f'Test Accuracy: {acc:.4f}')\n",
    "    print('-'*55)\n",
    "    \n",
    "    return acc, batch_size, learning_rate, epochs, seed\n",
    "\n",
    "# 使用示例:\n",
    "\"\"\"\n",
    "results = train(\n",
    "    mode='MM_SA_BA',\n",
    "    batch_size=16,  # 增大batch size\n",
    "    epochs=100,\n",
    "    learning_rate=0.001,\n",
    "    seed=42\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, \n",
    "    Dropout, \n",
    "    BatchNormalization, \n",
    "    Input, \n",
    "    concatenate,\n",
    "    Conv1D,\n",
    "    MaxPooling1D,\n",
    "    GlobalAveragePooling1D,\n",
    "    MultiHeadAttention,\n",
    "    LayerNormalization,\n",
    "    Reshape,\n",
    "    Add,\n",
    "    Activation\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "def make_img(t_img):\n",
    "    img = pd.read_pickle(t_img)\n",
    "    img_l = []\n",
    "    for i in range(len(img)):\n",
    "        img_l.append(img.values[i][0])\n",
    "    \n",
    "    return np.array(img_l)\n",
    "\n",
    "\n",
    "def reset_random_seeds(seed):\n",
    "    os.environ['PYTHONHASHSEED']=str(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "   \n",
    "               \n",
    "def create_model_snp():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(200,  activation = \"relu\")) \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, activation = \"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Dense(50, activation = \"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    return model\n",
    "\n",
    "def create_model_clinical():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(200,  activation = \"relu\")) \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, activation = \"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(50, activation = \"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))    \n",
    "    return model\n",
    "\n",
    "# DeepSNP版本\n",
    "def create_model_snp_deep():\n",
    "    model = Sequential([\n",
    "        # 第一层卷积块\n",
    "        Conv1D(64, 3, activation='relu', input_shape=(train_snp.shape[1], 1)),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(2),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        # 第二层卷积块\n",
    "        Conv1D(128, 3, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(2),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        # 第三层卷积块\n",
    "        Conv1D(256, 3, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        GlobalAveragePooling1D(),\n",
    "        \n",
    "        # 全连接层\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Dense(50, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Transformer版本\n",
    "def positional_encoding(length, depth):\n",
    "    positions = np.arange(length)[:, np.newaxis]\n",
    "    depths = np.arange(depth)[np.newaxis, :]/depth\n",
    "    angle_rates = 1 / (10000**depths)\n",
    "    angle_rads = positions * angle_rates\n",
    "    \n",
    "    pos_encoding = np.concatenate(\n",
    "        [np.sin(angle_rads), np.cos(angle_rads)],\n",
    "        axis=-1)\n",
    "    \n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    # Multi-head self attention\n",
    "    x = LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "    )(x, x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward\n",
    "    x = LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = Dense(ff_dim, activation=\"relu\")(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = Dense(inputs.shape[-1])(x)\n",
    "    return x + res\n",
    "\n",
    "def create_model_snp_transformer():\n",
    "    input_shape = train_snp.shape[1]\n",
    "    \n",
    "    inputs = Input(shape=(input_shape,))\n",
    "    \n",
    "    # Reshape and add positional encoding\n",
    "    x = Dense(64)(inputs)  # 投影到嵌入空间\n",
    "    x = Reshape((input_shape, 64))(x)\n",
    "    \n",
    "    # Add positional encoding\n",
    "    pos_encoding = positional_encoding(input_shape, 64)\n",
    "    x = x + pos_encoding\n",
    "    \n",
    "    # Transformer blocks\n",
    "    for _ in range(4):  # 4个Transformer块\n",
    "        x = transformer_encoder(\n",
    "            x,\n",
    "            head_size=32,\n",
    "            num_heads=4,\n",
    "            ff_dim=128,\n",
    "            dropout=0.1\n",
    "        )\n",
    "    \n",
    "    # Global pooling\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    \n",
    "    # Final dense layers\n",
    "    x = Dense(128, activation=\"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(50, activation=\"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "    return model\n",
    "\n",
    "\n",
    "def plot_classification_report(y_tru, y_prd, mode, learning_rate, batch_size,epochs, figsize=(7, 7), ax=None):\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    xticks = ['precision', 'recall', 'f1-score', 'support']\n",
    "    yticks = [\"Control\", \"Moderate\", \"Alzheimer's\" ] \n",
    "    yticks += ['avg']\n",
    "\n",
    "    rep = np.array(precision_recall_fscore_support(y_tru, y_prd)).T\n",
    "    avg = np.mean(rep, axis=0)\n",
    "    avg[-1] = np.sum(rep[:, -1])\n",
    "    rep = np.insert(rep, rep.shape[0], avg, axis=0)\n",
    "\n",
    "    sns.heatmap(rep,\n",
    "                annot=True, \n",
    "                cbar=False, \n",
    "                xticklabels=xticks, \n",
    "                yticklabels=yticks,\n",
    "                ax=ax, cmap = \"Blues\")\n",
    "    \n",
    "    plt.savefig('report_' + str(mode) + '_' + str(learning_rate) +'_' + str(batch_size)+'_' + str(epochs)+'.png')\n",
    "    \n",
    "\n",
    "\n",
    "def calc_confusion_matrix(result, test_label,mode, learning_rate, batch_size, epochs):\n",
    "    test_label = to_categorical(test_label,3)\n",
    "\n",
    "    true_label= np.argmax(test_label, axis =1)\n",
    "\n",
    "    predicted_label= np.argmax(result, axis =1)\n",
    "    \n",
    "    n_classes = 3\n",
    "    precision = dict()\n",
    "    recall = dict()\n",
    "    thres = dict()\n",
    "    for i in range(n_classes):\n",
    "        precision[i], recall[i], thres[i] = precision_recall_curve(test_label[:, i],\n",
    "                                                            result[:, i])\n",
    "\n",
    "\n",
    "    print (\"Classification Report :\") \n",
    "    print (classification_report(true_label, predicted_label))\n",
    "    cr = classification_report(true_label, predicted_label, output_dict=True)\n",
    "    return cr, precision, recall, thres\n",
    "\n",
    "\n",
    "\n",
    "def cross_modal_attention(x, y):\n",
    "    x = tf.expand_dims(x, axis=1)\n",
    "    y = tf.expand_dims(y, axis=1)\n",
    "    a1 = MultiHeadAttention(num_heads = 4,key_dim=50)(x, y)\n",
    "    a2 = MultiHeadAttention(num_heads = 4,key_dim=50)(y, x)\n",
    "    a1 = a1[:,0,:]\n",
    "    a2 = a2[:,0,:]\n",
    "    return concatenate([a1, a2])\n",
    "\n",
    "\n",
    "def self_attention(x):\n",
    "    x = tf.expand_dims(x, axis=1)\n",
    "    attention = MultiHeadAttention(num_heads = 4, key_dim=50)(x, x)\n",
    "    attention = attention[:,0,:]\n",
    "    return attention\n",
    "\n",
    "def simplified_attention(x, y):\n",
    "    \"\"\"简化的注意力机制\"\"\"\n",
    "    x = tf.expand_dims(x, axis=1)\n",
    "    y = tf.expand_dims(y, axis=1)\n",
    "    attention = MultiHeadAttention(num_heads=2, key_dim=25)(x, y)\n",
    "    return attention[:,0,:]\n",
    "    \n",
    "\n",
    "def multi_modal_model(mode, train_clinical, train_snp, train_img, snp_model_type='deepsnp'):\n",
    "    # 输入层\n",
    "    in_clinical = Input(shape=(train_clinical.shape[1]))\n",
    "    in_snp = Input(shape=(train_snp.shape[1]))\n",
    "    in_img = Input(shape=(train_img.shape[1], train_img.shape[2], train_img.shape[3]))\n",
    "    \n",
    "    # 特征提取\n",
    "    dense_clinical = create_model_clinical()(in_clinical)\n",
    "    # 选择SNP模型类型\n",
    "    if snp_model_type == 'deepsnp':\n",
    "        dense_snp = create_model_snp_deep()(in_snp)\n",
    "    else:  # transformer\n",
    "        dense_snp = create_model_snp_transformer()(in_snp)\n",
    "    dense_img = create_model_img()(in_img)\n",
    "    \n",
    "    # 简化的注意力机制\n",
    "    if mode == 'MM_SA_BA':\n",
    "        # 只保留最重要的跨模态注意力\n",
    "        img_clinical_att = simplified_attention(dense_img, dense_clinical)\n",
    "        snp_clinical_att = simplified_attention(dense_snp, dense_clinical)\n",
    "        merged = concatenate([img_clinical_att, snp_clinical_att, dense_img, dense_snp, dense_clinical])\n",
    "    else:\n",
    "        merged = concatenate([dense_img, dense_snp, dense_clinical])\n",
    "    \n",
    "    # 添加额外的整合层\n",
    "    merged = Dense(100, activation='relu')(merged)\n",
    "    merged = BatchNormalization()(merged)\n",
    "    merged = Dropout(0.5)(merged)\n",
    "    merged = Dense(50, activation='relu')(merged)\n",
    "    merged = BatchNormalization()(merged)\n",
    "    merged = Dropout(0.3)(merged)\n",
    "    \n",
    "    # 输出层\n",
    "    output = Dense(3, activation='softmax')(merged)\n",
    "    model = Model([in_clinical, in_snp, in_img], output)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def train(mode, batch_size, epochs, learning_rate, seed):\n",
    "    \n",
    "    # train_img = train_img.astype(\"float32\")\n",
    "\n",
    "    reset_random_seeds(seed)\n",
    "    class_weights = compute_class_weight(class_weight = 'balanced',classes = np.unique(train_label),y = train_label)\n",
    "    d_class_weights = dict(enumerate(class_weights))\n",
    "    \n",
    "    # compile model #\n",
    "    model = multi_modal_model(mode, train_clinical, train_snp, train_img)\n",
    "    model.compile(optimizer=Adam(learning_rate = learning_rate), loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
    "    callbacks = [\n",
    "        EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=10,\n",
    "            restore_best_weights=True,\n",
    "            mode='min'\n",
    "        ),\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=10,\n",
    "            min_lr=1e-6,\n",
    "            mode='min'\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # summarize results\n",
    "    history = model.fit([train_clinical,\n",
    "                         train_snp,\n",
    "                         train_img],\n",
    "                        train_label,\n",
    "                        epochs=epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        class_weight=d_class_weights,\n",
    "                        validation_split=0.1,\n",
    "                        verbose=1,\n",
    "                        callbacks = callbacks)\n",
    "                        \n",
    "                \n",
    "\n",
    "    score = model.evaluate([test_clinical, test_snp, test_img], test_label)\n",
    "    \n",
    "    acc = score[1] \n",
    "    test_predictions = model.predict([test_clinical, test_snp, test_img])\n",
    "    cr, precision_d, recall_d, thres = calc_confusion_matrix(test_predictions, test_label, mode, learning_rate, batch_size, epochs)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    plt.clf()\n",
    "    plt.plot(history.history['sparse_categorical_accuracy'])\n",
    "    plt.plot(history.history['val_sparse_categorical_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()\n",
    "    plt.savefig('accuracy_' + str(mode) + '_' + str(learning_rate) +'_' + str(batch_size)+'.png')\n",
    "    plt.clf()\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()\n",
    "    plt.savefig('loss_' + str(mode) + '_' + str(learning_rate) +'_' + str(batch_size)+'.png')\n",
    "    plt.clf()\n",
    "    \"\"\"\n",
    "    \n",
    " \n",
    "    \n",
    "    # release gpu memory #\n",
    "    K.clear_session()\n",
    "    del model, history\n",
    "    gc.collect()\n",
    "        \n",
    "        \n",
    "    print ('Mode: ', mode)\n",
    "    print ('Batch size:  ', batch_size)\n",
    "    print ('Learning rate: ', learning_rate)\n",
    "    print ('Epochs:  ', epochs)\n",
    "    print ('Test Accuracy:', '{0:.4f}'.format(acc))\n",
    "    print ('-'*55)\n",
    "    \n",
    "    return acc, batch_size, learning_rate, epochs, seed\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "16/16 [==============================] - 151s 9s/step - loss: 1.7660 - sparse_categorical_accuracy: 0.3740 - val_loss: 106.9528 - val_sparse_categorical_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 113s 7s/step - loss: 1.6988 - sparse_categorical_accuracy: 0.3415 - val_loss: 50.7016 - val_sparse_categorical_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 120s 8s/step - loss: 1.6669 - sparse_categorical_accuracy: 0.3821 - val_loss: 10.9511 - val_sparse_categorical_accuracy: 0.3571 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 108s 7s/step - loss: 1.5068 - sparse_categorical_accuracy: 0.4146 - val_loss: 11.4744 - val_sparse_categorical_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "14/16 [=========================>....] - ETA: 13s - loss: 1.3922 - sparse_categorical_accuracy: 0.4196"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-989597688337>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mseeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseeds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MM_SA_BA'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mm_a\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'MM_SA_BA'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-42b41bc386a0>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(mode, batch_size, epochs, learning_rate, seed)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;31m# summarize results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m     history = model.fit([train_clinical,\n\u001b[0m\u001b[1;32m    285\u001b[0m                          \u001b[0mtrain_snp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m                          train_img],\n",
      "\u001b[0;32m~/anaconda3/envs/idls24/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/idls24/lib/python3.8/site-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1740\u001b[0m                         ):\n\u001b[1;32m   1741\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1742\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1743\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1744\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/idls24/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/idls24/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/idls24/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    855\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/idls24/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m       (concrete_function,\n\u001b[1;32m    147\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    149\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/idls24/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1347\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1348\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1349\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_call_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1350\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/idls24/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/idls24/lib/python3.8/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1457\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1458\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/idls24/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "m_a = {}\n",
    "seeds = random.sample(range(1, 200), 1)\n",
    "for s in seeds:\n",
    "    acc, bs_, lr_, e_ , seed= train('MM_SA_BA', 8, 30, 0.001, s)\n",
    "    m_a[acc] = ('MM_SA_BA', acc, bs_, lr_, e_, seed)\n",
    "print(m_a)\n",
    "print ('-'*55)\n",
    "max_acc = max(m_a, key=float)\n",
    "print(\"Highest accuracy of: \" + str(max_acc) + \" with parameters: \" + str(m_a[max_acc]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_snp_deep():\n",
    "    model = Sequential([\n",
    "        # 第一层卷积块\n",
    "        Conv1D(64, 3, activation='relu', input_shape=(train_snp.shape[1], 1)),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(2),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        # 第二层卷积块\n",
    "        Conv1D(128, 3, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(2),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        # 第三层卷积块\n",
    "        Conv1D(256, 3, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        GlobalAveragePooling1D(),\n",
    "        \n",
    "        # 全连接层\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Dense(50, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Transformer版本\n",
    "def positional_encoding(length, depth):\n",
    "    positions = np.arange(length)[:, np.newaxis]\n",
    "    depths = np.arange(depth)[np.newaxis, :]/depth\n",
    "    angle_rates = 1 / (10000**depths)\n",
    "    angle_rads = positions * angle_rates\n",
    "    \n",
    "    pos_encoding = np.concatenate(\n",
    "        [np.sin(angle_rads), np.cos(angle_rads)],\n",
    "        axis=-1)\n",
    "    \n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    # Multi-head self attention\n",
    "    x = LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "    )(x, x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward\n",
    "    x = LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = Dense(ff_dim, activation=\"relu\")(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = Dense(inputs.shape[-1])(x)\n",
    "    return x + res\n",
    "\n",
    "def create_model_snp_transformer():\n",
    "    input_shape = train_snp.shape[1]\n",
    "    \n",
    "    inputs = Input(shape=(input_shape,))\n",
    "    \n",
    "    # Reshape and add positional encoding\n",
    "    x = Dense(64)(inputs)  # 投影到嵌入空间\n",
    "    x = Reshape((input_shape, 64))(x)\n",
    "    \n",
    "    # Add positional encoding\n",
    "    pos_encoding = positional_encoding(input_shape, 64)\n",
    "    x = x + pos_encoding\n",
    "    \n",
    "    # Transformer blocks\n",
    "    for _ in range(4):  # 4个Transformer块\n",
    "        x = transformer_encoder(\n",
    "            x,\n",
    "            head_size=32,\n",
    "            num_heads=4,\n",
    "            ff_dim=128,\n",
    "            dropout=0.1\n",
    "        )\n",
    "    \n",
    "    # Global pooling\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    \n",
    "    # Final dense layers\n",
    "    x = Dense(128, activation=\"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(50, activation=\"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nresults = train(\\n    mode='MM_SA_BA',\\n    batch_size=16,  # 增大batch size\\n    epochs=100,\\n    learning_rate=0.001,\\n    seed=42\\n)\\n\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Input, concatenate\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, MultiHeadAttention\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support, precision_recall_curve\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "import gc\n",
    "import os\n",
    "import random\n",
    "\n",
    "def reset_random_seeds(seed):\n",
    "    os.environ['PYTHONHASHSEED']=str(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "def create_model_snp():\n",
    "    model = Sequential([\n",
    "        Dense(100, activation=\"relu\"),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(50, activation=\"relu\"),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def create_model_clinical():\n",
    "    model = Sequential([\n",
    "        Dense(100, activation=\"relu\"),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(50, activation=\"relu\"),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.4)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def create_model_img():\n",
    "    model = Sequential([\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.4),\n",
    "        Conv2D(32, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.4),\n",
    "        Flatten(),\n",
    "        Dense(50, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def simplified_attention(x, y):\n",
    "    \"\"\"简化的注意力机制\"\"\"\n",
    "    x = tf.expand_dims(x, axis=1)\n",
    "    y = tf.expand_dims(y, axis=1)\n",
    "    attention = MultiHeadAttention(num_heads=2, key_dim=25)(x, y)\n",
    "    return attention[:,0,:]\n",
    "\n",
    "def multi_modal_model(mode, train_clinical, train_snp, train_img):\n",
    "    # 输入层\n",
    "    in_clinical = Input(shape=(train_clinical.shape[1]))\n",
    "    in_snp = Input(shape=(train_snp.shape[1]))\n",
    "    in_img = Input(shape=(train_img.shape[1], train_img.shape[2], train_img.shape[3]))\n",
    "    \n",
    "    # 特征提取\n",
    "    dense_clinical = create_model_clinical()(in_clinical)\n",
    "    dense_snp = create_model_snp()(in_snp)\n",
    "    dense_img = create_model_img()(in_img)\n",
    "    \n",
    "    # 简化的注意力机制\n",
    "    if mode == 'MM_SA_BA':\n",
    "        # 只保留最重要的跨模态注意力\n",
    "        img_clinical_att = simplified_attention(dense_img, dense_clinical)\n",
    "        snp_clinical_att = simplified_attention(dense_snp, dense_clinical)\n",
    "        merged = concatenate([img_clinical_att, snp_clinical_att, dense_img, dense_snp, dense_clinical])\n",
    "    else:\n",
    "        merged = concatenate([dense_img, dense_snp, dense_clinical])\n",
    "    \n",
    "    # 添加额外的整合层\n",
    "    merged = Dense(100, activation='relu')(merged)\n",
    "    merged = BatchNormalization()(merged)\n",
    "    merged = Dropout(0.5)(merged)\n",
    "    merged = Dense(50, activation='relu')(merged)\n",
    "    merged = BatchNormalization()(merged)\n",
    "    merged = Dropout(0.3)(merged)\n",
    "    \n",
    "    # 输出层\n",
    "    output = Dense(3, activation='softmax')(merged)\n",
    "    model = Model([in_clinical, in_snp, in_img], output)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train(mode, batch_size, epochs, learning_rate, seed):\n",
    "    reset_random_seeds(seed)\n",
    "    \n",
    "    # 计算类别权重\n",
    "    class_weights = compute_class_weight(\n",
    "        class_weight='balanced',\n",
    "        classes=np.unique(train_label),\n",
    "        y=train_label\n",
    "    )\n",
    "    d_class_weights = dict(enumerate(class_weights))\n",
    "    \n",
    "    # 创建和编译模型\n",
    "    model = multi_modal_model(mode, train_clinical, train_snp, train_img)\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['sparse_categorical_accuracy']\n",
    "    )\n",
    "    \n",
    "    # 回调函数\n",
    "    callbacks = [\n",
    "        EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=10,\n",
    "            restore_best_weights=True,\n",
    "            mode='min'\n",
    "        ),\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=5,\n",
    "            min_lr=1e-6,\n",
    "            mode='min'\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # 训练模型\n",
    "    history = model.fit(\n",
    "        [train_clinical, train_snp, train_img],\n",
    "        train_label,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        class_weight=d_class_weights,\n",
    "        validation_split=0.2,  # 增加验证集比例\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # 评估模型\n",
    "    score = model.evaluate([test_clinical, test_snp, test_img], test_label)\n",
    "    acc = score[1]\n",
    "    test_predictions = model.predict([test_clinical, test_snp, test_img])\n",
    "    \n",
    "    # 输出分类报告\n",
    "    pred_labels = np.argmax(test_predictions, axis=1)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(test_label, pred_labels))\n",
    "    \n",
    "    # 清理内存\n",
    "    K.clear_session()\n",
    "    del model, history\n",
    "    gc.collect()\n",
    "    \n",
    "    print(f'Mode: {mode}')\n",
    "    print(f'Batch size: {batch_size}')\n",
    "    print(f'Learning rate: {learning_rate}')\n",
    "    print(f'Epochs: {epochs}')\n",
    "    print(f'Test Accuracy: {acc:.4f}')\n",
    "    print('-'*55)\n",
    "    \n",
    "    return acc, batch_size, learning_rate, epochs, seed\n",
    "\n",
    "# 使用示例:\n",
    "\"\"\"\n",
    "results = train(\n",
    "    mode='MM_SA_BA',\n",
    "    batch_size=16,  # 增大batch size\n",
    "    epochs=100,\n",
    "    learning_rate=0.001,\n",
    "    seed=42\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 5s 208ms/step - loss: 1.9670 - sparse_categorical_accuracy: 0.3415 - val_loss: 15.3944 - val_sparse_categorical_accuracy: 0.2581 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 3s 161ms/step - loss: 1.6485 - sparse_categorical_accuracy: 0.3415 - val_loss: 3.3194 - val_sparse_categorical_accuracy: 0.2581 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 3s 178ms/step - loss: 1.1676 - sparse_categorical_accuracy: 0.5041 - val_loss: 1.8343 - val_sparse_categorical_accuracy: 0.3226 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 3s 168ms/step - loss: 1.2440 - sparse_categorical_accuracy: 0.4959 - val_loss: 1.5774 - val_sparse_categorical_accuracy: 0.3226 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 3s 185ms/step - loss: 0.9598 - sparse_categorical_accuracy: 0.5610 - val_loss: 1.4009 - val_sparse_categorical_accuracy: 0.5806 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 2s 150ms/step - loss: 0.8804 - sparse_categorical_accuracy: 0.5854 - val_loss: 1.1541 - val_sparse_categorical_accuracy: 0.7742 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 2s 139ms/step - loss: 0.8679 - sparse_categorical_accuracy: 0.5610 - val_loss: 0.9717 - val_sparse_categorical_accuracy: 0.7419 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 4s 240ms/step - loss: 0.7306 - sparse_categorical_accuracy: 0.6667 - val_loss: 0.9212 - val_sparse_categorical_accuracy: 0.7419 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 3s 156ms/step - loss: 0.8807 - sparse_categorical_accuracy: 0.5854 - val_loss: 1.0747 - val_sparse_categorical_accuracy: 0.7419 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 3s 185ms/step - loss: 0.6313 - sparse_categorical_accuracy: 0.6260 - val_loss: 1.0141 - val_sparse_categorical_accuracy: 0.7742 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 3s 172ms/step - loss: 0.6026 - sparse_categorical_accuracy: 0.6829 - val_loss: 1.0228 - val_sparse_categorical_accuracy: 0.7419 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 2s 148ms/step - loss: 0.7665 - sparse_categorical_accuracy: 0.5691 - val_loss: 0.9209 - val_sparse_categorical_accuracy: 0.7742 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 0.7956 - sparse_categorical_accuracy: 0.6667 - val_loss: 0.9046 - val_sparse_categorical_accuracy: 0.7742 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 2s 147ms/step - loss: 0.6308 - sparse_categorical_accuracy: 0.6829 - val_loss: 0.9090 - val_sparse_categorical_accuracy: 0.7742 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 2s 153ms/step - loss: 0.5312 - sparse_categorical_accuracy: 0.6585 - val_loss: 0.8984 - val_sparse_categorical_accuracy: 0.7742 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 2s 141ms/step - loss: 0.4930 - sparse_categorical_accuracy: 0.7317 - val_loss: 0.9236 - val_sparse_categorical_accuracy: 0.7742 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 2s 135ms/step - loss: 0.6387 - sparse_categorical_accuracy: 0.6585 - val_loss: 0.9267 - val_sparse_categorical_accuracy: 0.7742 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 3s 164ms/step - loss: 0.4824 - sparse_categorical_accuracy: 0.7642 - val_loss: 0.8056 - val_sparse_categorical_accuracy: 0.7742 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 3s 163ms/step - loss: 0.4865 - sparse_categorical_accuracy: 0.7398 - val_loss: 0.7258 - val_sparse_categorical_accuracy: 0.7742 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 3s 194ms/step - loss: 0.5984 - sparse_categorical_accuracy: 0.7073 - val_loss: 0.7007 - val_sparse_categorical_accuracy: 0.7742 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 2s 147ms/step - loss: 0.5865 - sparse_categorical_accuracy: 0.7480 - val_loss: 0.6622 - val_sparse_categorical_accuracy: 0.7742 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 2s 152ms/step - loss: 0.5038 - sparse_categorical_accuracy: 0.7561 - val_loss: 0.6075 - val_sparse_categorical_accuracy: 0.7742 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 2s 147ms/step - loss: 0.4946 - sparse_categorical_accuracy: 0.7724 - val_loss: 0.6151 - val_sparse_categorical_accuracy: 0.7742 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 3s 160ms/step - loss: 0.5332 - sparse_categorical_accuracy: 0.7236 - val_loss: 0.7595 - val_sparse_categorical_accuracy: 0.7742 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 2s 141ms/step - loss: 0.5011 - sparse_categorical_accuracy: 0.7480 - val_loss: 0.7110 - val_sparse_categorical_accuracy: 0.7742 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 2s 138ms/step - loss: 0.3626 - sparse_categorical_accuracy: 0.7805 - val_loss: 0.4827 - val_sparse_categorical_accuracy: 0.7742 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 0.4582 - sparse_categorical_accuracy: 0.7317 - val_loss: 0.4855 - val_sparse_categorical_accuracy: 0.7742 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 3s 154ms/step - loss: 0.6036 - sparse_categorical_accuracy: 0.7642 - val_loss: 0.5112 - val_sparse_categorical_accuracy: 0.7742 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 3s 154ms/step - loss: 0.4952 - sparse_categorical_accuracy: 0.7236 - val_loss: 0.6412 - val_sparse_categorical_accuracy: 0.7742 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 2s 144ms/step - loss: 0.4649 - sparse_categorical_accuracy: 0.7886 - val_loss: 0.5702 - val_sparse_categorical_accuracy: 0.7742 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 0.4210 - sparse_categorical_accuracy: 0.7398 - val_loss: 0.4336 - val_sparse_categorical_accuracy: 0.7742 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 3s 167ms/step - loss: 0.4568 - sparse_categorical_accuracy: 0.8049 - val_loss: 0.3983 - val_sparse_categorical_accuracy: 0.7742 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 4s 229ms/step - loss: 0.6839 - sparse_categorical_accuracy: 0.7317 - val_loss: 0.3578 - val_sparse_categorical_accuracy: 0.7742 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 3s 180ms/step - loss: 0.4959 - sparse_categorical_accuracy: 0.7886 - val_loss: 0.3579 - val_sparse_categorical_accuracy: 0.7742 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 2s 138ms/step - loss: 0.4040 - sparse_categorical_accuracy: 0.7480 - val_loss: 0.4394 - val_sparse_categorical_accuracy: 0.7742 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 2s 141ms/step - loss: 0.2949 - sparse_categorical_accuracy: 0.8049 - val_loss: 0.4385 - val_sparse_categorical_accuracy: 0.7742 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 2s 139ms/step - loss: 0.4164 - sparse_categorical_accuracy: 0.8130 - val_loss: 0.4130 - val_sparse_categorical_accuracy: 0.7419 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 2s 152ms/step - loss: 0.4239 - sparse_categorical_accuracy: 0.7724 - val_loss: 0.4178 - val_sparse_categorical_accuracy: 0.7742 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 0.4470 - sparse_categorical_accuracy: 0.7724 - val_loss: 0.4050 - val_sparse_categorical_accuracy: 0.7419 - lr: 5.0000e-04\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 2s 139ms/step - loss: 0.2959 - sparse_categorical_accuracy: 0.8211 - val_loss: 0.3897 - val_sparse_categorical_accuracy: 0.7742 - lr: 5.0000e-04\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 2s 140ms/step - loss: 0.3112 - sparse_categorical_accuracy: 0.8049 - val_loss: 0.3908 - val_sparse_categorical_accuracy: 0.7419 - lr: 5.0000e-04\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 2s 139ms/step - loss: 0.2747 - sparse_categorical_accuracy: 0.8699 - val_loss: 0.3778 - val_sparse_categorical_accuracy: 0.7742 - lr: 5.0000e-04\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 2s 145ms/step - loss: 0.4424 - sparse_categorical_accuracy: 0.7967 - val_loss: 0.4034 - val_sparse_categorical_accuracy: 0.7419 - lr: 5.0000e-04\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6147 - sparse_categorical_accuracy: 0.7222\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x10a152ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x10a152ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 256ms/step\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80        12\n",
      "           1       0.29      1.00      0.44         2\n",
      "           2       1.00      0.75      0.86         4\n",
      "\n",
      "    accuracy                           0.72        18\n",
      "   macro avg       0.76      0.81      0.70        18\n",
      "weighted avg       0.92      0.72      0.77        18\n",
      "\n",
      "Mode: MM_SA_BA\n",
      "Batch size: 8\n",
      "Learning rate: 0.001\n",
      "Epochs: 50\n",
      "Test Accuracy: 0.7222\n",
      "-------------------------------------------------------\n",
      "{0.7222222089767456: ('MM_SA_BA', 0.7222222089767456, 8, 0.001, 50, 53)}\n",
      "-------------------------------------------------------\n",
      "Highest accuracy of: 0.7222222089767456 with parameters: ('MM_SA_BA', 0.7222222089767456, 8, 0.001, 50, 53)\n"
     ]
    }
   ],
   "source": [
    "m_a = {}\n",
    "seeds = random.sample(range(1, 200), 1)\n",
    "for s in seeds:\n",
    "    acc, bs_, lr_, e_ , seed= train('MM_SA_BA', 8, 50, 0.001, s)\n",
    "    m_a[acc] = ('MM_SA_BA', acc, bs_, lr_, e_, seed)\n",
    "print(m_a)\n",
    "print ('-'*55)\n",
    "max_acc = max(m_a, key=float)\n",
    "print(\"Highest accuracy of: \" + str(max_acc) + \" with parameters: \" + str(m_a[max_acc]))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idls24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
